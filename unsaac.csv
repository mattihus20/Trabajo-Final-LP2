Universidad;Titulo;Autor;Grado;Asesor;Resumen;Año
Universidad Nacional de San Antonio Abad del Cusco;Aplicación de visión artificial en la estimación del peso corporal del cuy;Zapata Ttito, Abel Gabriel;Ingeniero Informático y de Sistemas;Ormeño Ayala, Yeshica Isela;"La estimación del peso es un tema de investigación que ha sido abordado usando técnicas de visión artificial, siendo la más reciente: la red neuronal convolucional (CNN), la cual ha permitido obtener buenos resultados en la estimación del peso animal como: el cerdo, la vaca y el pescado. En la región del Cusco, el peso del cuy es un factor muy importante en la crianza de cuyes tanto en el sector comercial (productores) y el ´am bito académico (investigadores), porque permite realizar un monitoreo al cuy durante su ciclo productivo. Este trabajo propone como objetivo general la aplicación de visión artificial mediante la adaptación de un modelo Convolutional Neural Network (CNN) en la estimación del peso del cuy. Para lograr este objetivo: primero, se realizó una revisión bibliográfica de investigaciones sobre la estimación del peso animal; segundo, se recolectó 1561 imágenes de cuyes y sus respectivos pesos para construir un dataset de imágenes, máscaras y pesos de cuyes; tercero, se adaptó el modelo Mask R-CNN añadiéndole una rama que permita estimar el peso del cuy; y cuarto, se analizó los resultados obtenidos después del entrenamiento del modelo para mostrar la precisión que se obtiene en la estimación del peso del cuy. También se procedió a la implementación de un prototipo que sirva como una herramienta en la estimación del peso del cuy. Como resultado se obtuvo un R2=80 % de precisión en la estimación del peso del cuy y un MAPE de 12.41 %.";2022
Universidad Nacional de San Antonio Abad del Cusco;Implementación de la red de acceso a internet por fibra óptica para el desarrollo de las clases virtuales de la Institución Educativa Wiñaypaq de la comunidad campesina de Huandar del distrito de Pisac;Usca Abal, Milton;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"El presente trabajo de investigación tiene como objetivo principal la implementación de la red de acceso a internet por fibra óptica para el desarrollo de las clases virtuales. Sobre el método utilizado, el trabajo fue de alcance descriptivo, de enfoque cuantitativo y de tipo básico; la población lo conforman 70 estudiantes y docentes de la institución educativa Wiñaypaq de la comunidad campesina de Huandar del distrito de Pisac. Para solucionar el problema de conectividad de internet se realizó el tendido de fibra óptica SPAM 200 desde la terminal de línea óptica (OLT) ubicado en el distrito de Pisac hasta la terminal de nodo óptico (ONT) ubicado en la institución educativa, utilizando para el propósito los postes de energía de media y baja tensión de la empresa Electro Sur Este, en un recorrido de 2200 metros, a su vez se realizó la instalación de dos antenas direccionales para proporcionar internet Wifi a los alumnos de la institución y la conexión a una red de datos del centro de cómputo de la institución, para el buen uso del internet se realizó capacitaciones a los docentes en plataformas de desarrollo de clases virtuales.";2022
Universidad Nacional de San Antonio Abad del Cusco;Evaluación de arquitecturas Deep Learning para identificar anomalías por deficiencia de macronutrientes en Persea Americana variedad Hass;Machaca Quispe, Lucero Betzabe;Ingeniero Informático y de Sistemas;Carbajal Luna, Julio Cesar;La fertilidad del suelo es vital para el desarrollo de los cultivos de Persea Americana y una beneficiosa producción de frutos, este desarrollo se ve afectado por la deficiencia de nutrientes (macro y micro nutrientes) en el suelo. Las características tempranas se presentan en las hojas provocando decoloraciones, manchas y en algunos casos necrosis. En los macronutrientes se consideran seis clases críticas para el cultivo como son Calcio, Potasio, Magnesio, Nitrógeno, Fósforo y Azufre, la dificultad de identificar al macronutriente que ocasiona la aparición de anomalías en las hojas corresponde a un problema de clasificación de imágenes. Las redes neuronales convolucionales han demostrado un gran desempeño en las tareas de visión por computadora, esencialmente en la clasificación de imágenes por este motivo la solución propone emplear las arquitecturas de redes neuronales profundas Inception-v3, DenseNet169 y MobileNet por su alto rendimiento. Para entrenar las CNNs se construyó un dataset original y primero en su tipo de 6,090 imágenes distribuidas en siete categorías que se recolectaron en cuatro periodos, en el sector de Molinopata, Abancay - Apurímac, aún con esta cantidad de imágenes es insuficiente para entrenar una CNN desde cero. Por esta razón se empleó la transferencia de aprendizaje en la solución como estrategia de entrenamiento, adicionalmente beneficia el desarrollo de la solución reduciendo el costo computacional y los tiempos de entrenamiento. Se construyó un prototipo basado en una arquitectura API y desplegado en el servidor local con finalidad de mostrar los resultados de manera dinámica para un usuario final. Los resultados obtenidos de las métricas de evaluación aplicadas al subconjunto de validación de Persea Americana Hass Dataset proporcionan un análisis del comportamiento de las CNNs en la tarea clasificación de las hojas de Persea Americana variedad Hass. Se obtuvo tasas de acierto del 85.86%, 84.64% y 83.29% de Inception-v3, MobileNet y DenseNet169 respectivamente. Resultando ser la CNN Inception-v3 la sobresaliente para el problema de investigación.;2019
Universidad Nacional de San Antonio Abad del Cusco;Implementación de técnicas de minería de texto para la clasificación de tickets de soporte en la oficina de Tecnologías de la Información de EGEMSA;Alejo Hirpahuanca, Fernando;Ingeniero Informático y de Sistemas;Palomino Olivera, Emilio;"En EGEMSA cuando un colaborador de la empresa solicita un ticket de soporte mediante correo electrónico, llamada telefónica o de manera presencial; el personal de la oficina de Tecnologías de la Información (TI) revisa dicha solicitud y lo deriva a un especialista de soporte para su solución inmediata. A medida que se incrementaba la cantidad de solicitudes de servicio de TI, el personal responsable de atender los tickets, dedicaba mucho tiempo evaluando cada descripción del ticket y tratando de asignarle su categoría correspondiente. Como resultado de esta tarea manual, la mayoría de las veces el personal de la oficina de TI completaba con la etiqueta “Otros” o “Ninguno” para estos tickets; esto implicaba una dificultad crucial al momento de generar informes ya que no contemplaba el detalle de cada categoría. Es por ello que se implementó las técnicas de minería de texto para la clasificación de los tickets de soporte, en efecto se construyó un modelo clasificador de tickets para categorizar el nuevo ticket en función de su descripción. Asimismo, el conjunto de datos que se utilizó fueron datos internos de la empresa importados desde su sistema de mesa de ayuda. Se recolectó alrededor de 3000 tickets de soporte, considerando el título, la descripción del ticket, la fecha y su categoría. Para el entrenamiento del modelo se dividió el 75% del total de tickets y para las pruebas el 25%. Al final del entrenamiento y pruebas, el modelo SVC lineal alcanzó una precisión del 75% al hacer predicciones para los nuevos tickets. La contribución de las técnicas de minería de texto para la clasificación de los tickets en la oficina de tecnologías de la información fue automatizar el proceso de clasificación, mejor obtención de informes de servicios de TI, y la satisfacción de los encargados de la oficina de TI.";2022
Universidad Nacional de San Antonio Abad del Cusco;Identificación de establecimientos comerciales no registrados en mapas digitales;Huarayo Quispe, Joel Frank;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"El presente trabajo de investigación busca identificar establecimientos comerciales mediante imágenes de Google Street View (GSV) debido a que facilita obtener imágenes de calles, pero existen ciertas dificultades como: ruido, oclusión de personas, carros, arboles, etc. Para abordar este problema, se propone un método que hace uso de procesamiento de datos espaciales realizadas en un entorno GIS y técnicas de Deep Learning. Primeramente, se creó un algoritmo para descargar automáticamente imágenes de GSV orientadas a las fachadas de los edificios, analizando la geometría de mapas en OSM mediante el software QGIS, con el fin de construir un dataset de imágenes de establecimientos comerciales; para luego entrenar un modelo capaz de detectar y clasificar establecimientos comerciales, luego se calcula su ubicación geográfica tomando en cuenta los metadatos obtenidos al descargar las imágenes. Esta información permite conocer la ubicación y el tipo aproximado de negocios que se hallan en ciertas zonas urbanas de la ciudad del Cusco.";2021
Universidad Nacional de San Antonio Abad del Cusco;Construcción de un extractor de características basado en modelos pre-entrenados de redes neuronales convolucionales, para la identificación de imágenes de pinturas coloniales de la ciudad del Cusco;Centeno Delgado, Harried All;Ingeniero Informático y de Sistemas;Carbajal Luna, Julio Cesar;"El presente trabajo pretende identificar imágenes de pinturas coloniales de la ciudad del Cusco. En específico, a la hora de capturar imágenes; estas pueden presentar diferentes desafíos tales como distorsiones, capturas desde diferentes ángulos, similaridad entre imágenes de diferentes clases y estilos artísticos parecidos entre pinturas de diferentes clases. Sin embargo, la verdadera dificultad radica al momento de representar una imagen (extraer características) a través de un vector, este inconveniente puede ser mitigado de varias formas, ya sea utilizando descriptores locales o globales tales como SIFT y SURF, respectivamente. No obstante, en este trabajo se pretende utilizar modelos pre-entrenados de redes neuronales convolucionales, para conseguir un extractor de características más robusto, debido a que estos presentan una tasa de acierto elevada frente a otros métodos tradicionales de visión computacional. Así mismo, se comparan los resultados obtenidos entre los modelos pre-entrenados Inception-V3 y ResNet y el nuevo extractor de características propuesto en este trabajo; aquel basado en la combinación de los modelos pre-entrenados previos. De esta comparación, se identifico que los resultados generados por el método propuesto son superiores a los resultados generados por Inception-V3 y ResNet.";2021
Universidad Nacional de San Antonio Abad del Cusco;Prototipo de un sistema portátil para el tratamiento preventivo de ulceraciones por presión del pie diabético;Aslla Sullca, Justa Marisol;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"El presente trabajo tiene como objetivo la implementación de un sistema portátil en pacientes con diabetes para el tratamiento preventivo de ulceraciones del pie diabético, para lo cual se desarrollará una aplicación móvil y un sistema web para monitorear la presión de pisada de un paciente, esto con la integración de una plantilla basada en sensores de velostat para captar información de presión de pisadas, esta información es enviada al celular del paciente mediante el microprocesador ESP32. Una de las consecuencias de la diabetes es el pie diabético en el que del total de las personas que sufren esta patología el 25% tienen riesgo de padecer úlceras en la planta del pie debido a presiones excesivas a lo largo de su vida. Esta lesión es la principal causa de amputación de miembros en pacientes con diabetes. En este contexto es trascendental el tratamiento preventivo de ulceraciones en el pie, pero el que se realiza es en base a factores subjetivos, es decir, variables dependientes del factor humano, tales como; la experiencia, visualización de características superficiales como enrojecimiento de la piel, aparición de callos entre otros. Se construyó una plantilla con 10 sensores, las cuales interactúan con el teléfono celular del paciente a través del protocolo de comunicación Bluetooth del microcontrolador ESP32. Con este trabajo de investigación se pone a disposición una herramienta tecnológica de apoyo al tratamiento preventivo de ulceraciones de la planta del pie generada por la falta de sensibilidad como consecuencia de la diabetes.";2021
Universidad Nacional de San Antonio Abad del Cusco;Evaluación de técnicas de Change detection utilizando imágenes satelitales Landsat 8 para identificar cambios en la superficie causados por la minería;Zela Quirita, Sheyla Ruby;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;La minería es una de las actividades económicas más importantes para el Perú, la cual genera cambios sobre la cobertura terrestre, por ende es necesario cuantificar dichos cambios. Change detection es un tipo de enfoque de interpretación, el cual está orientado a analizar lo que ha cambiado entre dos o más imágenes adquiridas con un cierto intervalo de tiempo. Este enfoque es de gran importancia debido a las múltiples aplicaciones que tiene.Change detection aplicado a zonas mineras mediante imágenes satelitales es una tarea difícil, dado que las imágenes obtenidas mediante el satélite pueden tener diferentes variantes: brillo, contraste, saturación, oclusiones, por nombrar algunos. Actualmente no se ha encontrado trabajos que busquen determinar la técnica de change detection más óptima para este problema. Por lo tanto, es necesario evaluar las técnicas que resuelvan este problema de una manera más precisa. Se propone evaluar las técnicas Diferenciación de Imágenes, Ratioing, Change Vector Analysis, Normalized Diérence Vegetation Index, Tasseled Cap Transformation, CVA-TCT y PCA-Kmeans. Por último, se espera que los resultados permitan una mejor comprensión de las técnicas de change detection aplicado al problema de identi_cación de cambios generados por la minería. De igual manera se espera que este trabajo motive al desarrollo de futuros trabajos de carácter tecnológico que tengan como base la preservación del ecosistema. Se creará además un dataset de imágenes de zonas mineras, esperando que facilite el desarrollo de futuros trabajos en esta área.;2021
Universidad Nacional de San Antonio Abad del Cusco;Algoritmo para el problema data streaming clustering para conjuntos amorfos y con outliers;Campos Ardiles, Isaac;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;El presente trabajo tiene la finalidad de investigar sobre el tema de Clustering porque es un campo importante dentro de Machine Learning y ha sido ampliamente estudiado durante varios años. Como resultado, se desarrollaron muchos algoritmos que resuelven este problema, los cuales tal como están planteados no pueden resolver el caso particular que será objeto de este estudio. Por ello un nuevo problema llama- do Data Streaming Clustering fue propuesto y fue objeto de investigación de muchos estudios. Este problema está definido como el clustering de un flujo de datos recibidos continuamente. Data Streaming clustering tiene como objetivo encontrar y mantener un conjunto de clusters válidos en un continuo y posiblemente ilimitado flujo de datos. Teniendo en cuenta las limitantes actuales en la tecnología como la capacidad de la memoria o limitaciones en el tiempo computacional. Es importante tener en cuenta que los algoritmos para el problema de clustering no pueden resolver eficientemente el problema en estudio sin una previa modificación, ya que no toman en cuenta estas características. Debido a las características de este problema los algoritmos planteados para resolver el problema de Data Streaming clustering pueden ser usados para minería de datos con características especiales como outliers o ruido en los datos, como grabaciones telefónicas, transacciones bancarias, información de redes sociales. En esta investigación se presenta el diseño e implementación de un algoritmo para Data Streaming Clustering para datasets con clusters irregulares, outliers y sin necesidad de un conocimiento previo del número de clusters, además se realiza un análisis y discusión sobre los resultados.;2021
Universidad Nacional de San Antonio Abad del Cusco;Construcción de un prototipo de sistema para clasificar enfermedades en las hojas de cafeto basado en visión computacional;Puclla Zegarra, Erwin Jharin;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"Existen enfermedades y plagas que afectan al crecimiento del cafeto que son clasiﬁcadas haciendo uso de métodos tradicionales, manuales y visuales generando un margen de error en los resultados y tiempos de respuesta prolongados en los diagnósticos, en consecuencia, se tiene mayor índice de expansión de enfermedades en los cultivos de cafeto, mala calidad de granos y disminución en la producción del café. Sin embargo carecemos de una herramienta tecnológica eﬁcaz y automática para la clasiﬁcación de enfermedades, por ello la necesidad de construir un prototipo de sistema de clasiﬁcación de enfermedades en las hojas del cafeto basado en visión computacional, y mostrar información técnica de las mismas para plantear un mejor control; las enfermedades afectan al fruto como a las hojas, en algunos casos se puede apreciar en la raíz de la planta, entre las enfermedades que dañan las hojas se tiene; Leucoptera Coﬀeella, Mycena Citricolor, Hemileia Vastatrix. Para contrarrestar las enfermedades de manera eﬁciente en tiempo prudente se construye un prototipo de sistema de clasiﬁcación de enfermedades constituido en 3 partes, primero, la construcción de un conjunto de datos (dataset de imágenes) de validación y entrenamiento formado por 1000 imágenes de enfermedades de interés, en segundo lugar, se diseña una arquitectura de red neuronal convolucional para la fase de entrenamiento y clasiﬁcación de la enfermedad, así mismo, se propone modelos de redes neuronales convolucionales ya construidos como el modelo VGG-16, AlexNet e InceptionV3 los cuales fueron entrenados en un entorno virtual denominado Google Colaboratory; la imagen de entrada a ser clasiﬁcada sufre transformaciones de preprocesamiento como técnicas de segmentación de imágenes, ecualización de imágenes y ﬁltros de suavizado; ﬁnalmente se construye el prototipo del sistema haciendo uso del modelo ya entrenado y los módulos de segmentación de imágenes basado en color y umbralizacio´n para poder separar la región sana y enferma solo en caso de Hemileia Vastatrix, así mismo, se complementa con la información técnica de las enfermedades a tratar tales como biología, agente causal, daño y control. Desarrollado en entorno de escritorio, así el proceso de clasiﬁcación se realiza en tiempo real, sin conocimiento previo adquirido a través de la experiencia, menor margen de error y es diagnosticado inmediatamente por los especialistas o caﬁcultores evitando la propagación masiva de la enfermedad.";2020
Universidad Nacional de San Antonio Abad del Cusco;Diseño y evaluación de un modelo basado en una red de cápsulas de matrices con em routing utilizando una red convolucional densa;Blas Huaman, Washington;Ingeniero Informático y de Sistemas;Ormeño Ayala, Yeshica Isela;"Actualmente la arquitectura de Aprendizaje Profundo (Deep Learning) con mayor éxito y más usado en reconocimiento y clasificación de imágenes, visión computacional, conducción automática de vehículos; es la Red Neuronal Convolucional (Convolutional Neural Network o CNN). Sin embargo las CNNs presentan limitaciones ya que no son robustas cuando existen transformaciones en el objeto evaluado, es decir un ligero cambio de la posición del objeto provocará que las CNNs modifiquen su predicción. Aunque este problema puede ser reducido incrementando el conjunto de datos durante el entrenamiento, esto no garantiza que la red sea robusta para una nueva modificación en la posición que pueda estar presente en el conjunto de datos de prueba. Para superar estos inconvenientes surgen las Redes de Cápsulas (Capsule Network o CapsNet), que mejoran la clasificación de imágenes cuando estos presentan rotación, inclinación u otra orientación diferente, facilitando la obtención de información en la verificación de sus posiciones relativas con un menor número de datos. Por otro lado las redes de Cápsulas Matriciales con Enrutamiento EM, que son una mejora de las redes de Cápsulas con Enrutamiento Dinámico, presentan cápsulas donde cada cápsula está conformada por una unidad de activación que representan la presencia de un objeto y una matriz de pose de 4x4 que aprende a representar la relación espacial entre el objeto y el espectador, obteniendo así información más precisa. Ambas arquitecturas de redes de cápsulas presentan como primera capa de entrada una red de convolución estándar, pero un problema inherente a una (CNN) es cuando tiende a perder información a medida que la red se hace más profunda debido a la anulación del gradiente (vanishing gradient), es decir el gradiente tiende a ser igual a cero durante el proceso de aprendizaje cuando una red tiene muchas capas. Como una alternativa se tiene la arquitectura de Red Convolucional Densamente Conectado (DenseNet) que resuelve este problema asegurando un flujo máximo de información, donde para cada capa, las características obtenidas en todas las capas anteriores se utilizan como entradas, y sus propias características obtenidas se utilizan como entradas en todas las capas posteriores, esto conduce a un mejor flujo de gradiente en comparación con las capas de convolución apiladas directamente. Por tanto, en este trabajo se diseña y evalúa una arquitectura de Cápsulas Matriciales con Enrutamiento EM, reemplazando su primera capa de red convolucional simple (ReLU Conv1) por una red convolucional densa (DenseNet), para mostrar una mejora en el tiempo y precisión de entrenamiento frente al modelo base de redes de Cápsulas Matriciales con Enrutamiento EM, utilizando el conjunto de datos SmallNORB que está destinado a experimentos de reconocimiento de imágenes de objetos en 3D.";2020
Universidad Nacional de San Antonio Abad del Cusco;Identificación de métodos de procesamiento digital de imágenes bacteriológicas microscópicas para el diagnóstico de tuberculosis;Ovalle Gamarra, Gional;Ingeniero Informático y de Sistemas;Rozas Huacho, Javier Arturo;"El diagnóstico de la Tuberculosis (TBC) es un proceso fundamental para iniciar un tratamiento médico y/o farmacológico exitoso, sin embargo este carece de un método de diagnóstico que sea económico y confiable ya que la TBC es una enfermedad infecto contagioso que se hace multidrogo resistente cuando se realiza un diagnóstico tardío o en una etapa avanzada; Este retraso se debe a que los laboratoristas de los centros especializados de diagnóstico tienen sobre carga laboral, como cansancio mental y físico, generando la disminución de la capacidad de identificación y por ende el conteo de bacterias de TBC, en este sentido el objetivo del presente trabajo es identificar métodos de procesamiento digital de imágenes adecuadas para el diagnóstico de este mal (ver ilustración 40, página 73), en este contexto se examinan algoritmos de color (RGB y HSV), algoritmos de morfología (erosión y dilatación) y algoritmos de borde (Canny y Sobel). Para el conteo de los bacilos se desarrolló un módulo basada en tres condiciones (perímetro, tangente y diámetro) para determinar a posibles objetos de interés, la importancia de este trabajo es la posibilidad de contar con una herramienta tecnológica de diagnóstico confiable de TBC, en este sentido el presente estudio tiene un enfoque cuantitativo analítico de estimación de características operativas de confiabilidad (sensibilidad, especificidad) y exactitud de pruebas diagnósticas, ya que va a comparar el desempeño de diagnóstico de esta herramienta contra técnicas de laboratorio utilizadas como pruebas de rutina o de referencia (Gold Standar), el tamaño de la muestra es de 92 muestras con un nivel de confianza del 75 % provenientes de Redes de Salud y hospitales de la Región Cusco, obteniéndose una herramienta tecnológica de diagnóstico de la tuberculosis basado en procesamiento de imágenes con un nivel de confianza mayor al 95 % y una exactitud mayor al 96 %.";2020
Universidad Nacional de San Antonio Abad del Cusco;Análisis masivo de datos en twitter para identificación de opinión;Olarte Chullo, Albert Edison;Ingeniero Informático y de Sistemas;Carbajal Luna, Julio Cesar;Las redes sociales están jugando un papel muy importante en nuestra sociedad, y los microblogging es una parte importante de la comunicación hoy en día. Esto permite que los usuarios puedan publicar una opinión acerca de un determinado tema haciendo uso de internet y los sitios web en un repositorio grande de información. Las redes sociales como twitter, google+, facebook y whatsapp, contienen cantidad de publicaciones en sus sitios web. Esto hace de estas plataformas una fuente para exploración de información haciendo uso de métodos de Inteligencia Artificial, debido a la masiva cantidad de información que en casos como twitter llegan a ser millones por día alrededor del mundo y hoy necesitamos aprovechar esta vasta información para interpretar los datos con la finalidad de saber cuántas opiniones son realizadas positivamente y cuantas son negativas.;2020
Universidad Nacional de San Antonio Abad del Cusco;Aplicación del método de agrupamiento lineal en inferencia de redes genéticas probabilísticas aplicado al Plasmodium Falciparum;Yunguri Ttito, Juan Christian;Ingeniero Informático y de Sistemas;Carbajal Luna, Julio Cesar;Las reacciones químicas que resultan de la expresión de genes son complejas y aun no se entienden completamente. Se conoce que los genes envían, reciben y procesan la información para formar una compleja red de comunicación, pero la arquitectura y la dinámica de estas redes no es totalmente conocida. De esta forma, un problema importante dentro del campo de la biología sistémica es determinar cómo los genes se relacionan entre si dentro de la célula. Este proceso se conoce como inferencia de redes gen éticas. La inferencia de redes gen éticas a partir de datos de expresión es un problema abierto debido a la alta dimensionalidad (número de genes) y al pequeño número de muestras disponibles, incluso considerando el hecho de que las redes sean escasas (número limitado de genes de entrada por gen objetivo). De esta forma, podemos encontrar varias técnicas que ayudan a aliviar el problema de la alta dimensionalidad, en este trabajo nos centramos en corroborar la efectividad del método de Agrupamiento Lineal, el cual infiere las redes gen éticas a partir de particiones en el espacio del reticulado Booleano, inducidos por combinaciones lineales de los valores de los genes predictores. De este modo el número de configuraciones de los valores de los predictores muestran una función lineal en vez de una función exponencial en función al número de genes, de esta forma es aplicada una selección local de características (genes predictores) para cada gen con el fin de hacer la inferencia. Este trabajo analiza el método de Agrupamiento Lineal aplicado a un conjunto de datos del microarray del Plasmodium Falciparum, uno de los agentes que produce la malaria, demostrando la validez de esta técnica en datos reales, habiendo sido capaz de producir conocimiento ya descubierto anteriormente y ayudando a aliviar el problema de dimensionalidad.;2016
Universidad Nacional de San Antonio Abad del Cusco;Chatbot generativo en el idioma español utilizando la arquitectura de red neuronal Transformer;Uscamaita Quispetupa, Marycel;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"Los agentes conversacionales o chatbot han ido progresando en los últimos años gracias a la inteligencia artificial. Siendo Eliza (1966), uno de los primeros programas en procesar lenguaje natural. Eliza busca patrones en la frase escrita por el usuario, para luego responder con una “frase modelo"" registrada en su base de datos. Por otro lado, tenemos el actual Google Assistant, un asistente virtual en desarrollo, compuesto por módulos de deep learning, además posee la tecnología Google Duplex que utiliza Redes Neuronales Recurrentes (RNN) y módulos de Long short-term memory (LSTM) en su núcleo, con el fin de ayudar a los usuarios a completar tareas específicas. Si bien las RNNs se utilizan para modelar problemas de secuencia temporal, como la traducción automática neural (Casacuberta and Peris, 2017), estas redes procesan la entrada de manera secuencial, es decir, requieren más tiempo de entrenamiento y mayores recursos de hardware; en contraste a esto, surge transformer, una arquitectura encoder-decoder que procesa de forma paralela la secuencia de entrada mientras usa un mecanismo de self-attention (Gouws et al., 2018); por esta razón, se implementó un chatbot generativo en el idioma español utilizando la arquitectura de red neuronal transformer siguiendo el método propuesto por (Perez, 2016). En este proyecto se entrenaron y probaron varios modelos basados en Vanilla y Universal transformer; los mejores modelos fueron evaluados, obteniendo un 60% de respuestas buenas y un 76% de respuestas coherentes.";2019
Universidad Nacional de San Antonio Abad del Cusco;Implementación de un prototipo de un sistema embebido para el monitoreo del consumo de petróleo en vehículos motorizados;Maita Torres, Gabriel;Ingeniero Informático y de Sistemas;Pillco Quispe, Jose Mauro;Pese al creciente desarrollo de la tecnología a en nuestro País, la mayoría de las empresas de transporte público no poseen sistemas que permitan visualizar los niveles de combustible en los tanques de sus unidades vehiculares, en tal razón la medición de control del nivel de combustible se realiza de manera primitiva e imprecisa, llevando a tener falta de control sobre los niveles de combustible en todo momento. El impacto de la TIC ha tenido gran incidencia en los sistemas tradicionales, es as que se han hecho más aplicables los sistemas embebidos en la solución de problemas específicos, desarrollando tecnología a a medida. El dispositivo a medida al que se refiere en esta investigación es un sistema embebido, con el cual se permite al usuario visualizar en tiempo real medidas del nivel de combustible de un tanque a escala. Esta visualización se aprecia en una pantalla y a su vez se almacena en la nube datos exactos de la ubicación y lo referente a datos de la unidad vehicular y del conductor. Adicional a la medición, geo posición y demás datos de dicha unidad, se plantea un sistema de mensajes de alerta de robo de combustible, los elementos del sistema embebido son: un sensor del nivel de combustible el cual fue desarrollado en el presente trabajo basado en un principio capacitivo, un módulo GPS para enviar la ubicación, un SIM 900 para enviar mensajes de texto con alertas de robo de combustible mediante comandos AT y un sistema web para la gestión y accesibilidad de estos datos a través del Internet. Los resultados del sistema embebido fueron que el sensor capacitivo hace una correspondencia entre el porcentaje de volumen contenido y la frecuencia generada en el tiempo de carga y descarga, mientras que el GPS indica posición con un margen de 10 metros y el tiempo de envío de SMS de alerta depende la red de telefonía del chip.;2019
Universidad Nacional de San Antonio Abad del Cusco;Aplicación del problema del agente viajero a la recolección de residuos sólidos de la Municipalidad Distrital de San Jerónimo;Pauccara Pinares, Daniel;Ingeniero Informático y de Sistemas;Carbajal Luna, Julio Cesar;"En la gestión de los residuos sólidos en la Municipalidad Distrital de San Jerónimo se presenta varios problemas. Uno de los más resaltantes es la ausencia de una ruta optima de recojo de residuos debido a que los trazos son hechos por simple cálculo. El problema considerado en este proyecto es: mal diseño de rutas para los carros recolectores (las distancias no son las más cortas). Esto genera insatisfacción a los ciudadanos y mayores gastos de operación. En este proyecto se va a utilizar el método de Branch and Bound para minimizar las distancias que los carros recolectores necesitan para realizar su trabajo. Este problema tiene diversas aplicaciones tales como la planificación, logística, fabricación de circuitos electrónicos, etc. A pesar de que este problema es computacionalmente complejo, existen métodos heurísticos que dan soluciones eficientes. El método Branch and Bound es un método heurístico que sirve para resolver problemas de optimización. Se divide en dos partes: estrategias de ramificación y estrategias de poda. Este método ha sido utilizado en diversos problemas como: la mochila, programación lineal, problema del viajante, etc. El método mencionado se aplicará para el enrutamiento de los carros recolectores de basura; se va a optimizar el trayecto que los carros necesitan para cumplir sus labores, de esta forma se prestara un servicio eficiente a la ciudadanía, además, se consigue reducir los gastos de operación. Para este _n se van a desarrollar estrategias de ramificación y poda siguiendo el método de Branch and Bound. Se construirá un aplicativo donde se apreciaran los resultados de la investigación. Los resultados de la investigación son: una aplicación web con las siguientes características: configuración inicial del garaje municipal, punto de llegada final del vehículo, registro de conductores, vehículos, zonas de recolección, puntos de recolección, diseño de la rutas actuales de recolección, optimización de rutas y rastreo vehicular; y una aplicación móvil donde el conductor podrá visualizar la ruta a seguir.";2019
Universidad Nacional de San Antonio Abad del Cusco;Algoritmo de optimización multiobjetivo para el problema center-based clustering para conjuntos con outliers;Leon Malpartida, Jared;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"Clustering (agrupamiento) es usualmente considerado el problema más importante del aprendizaje automático no supervisado. Al igual que los problemas no supervisados, el problema del clustering consiste en descubrir patrones de agrupamiento. En particular, se busca agrupar un conjunto de datos no etiquetados en conjuntos llamados clusters (o grupos). Dada la naturaleza del problema, este aparece en multitud de áreas de investigación como: compresión de datos, análisis de imágenes, bioinformática, y minería de datos. A la fecha, se han diseñado multitud de algoritmos y modelos de clustering. También, se ha generalizado el tipo de datos con los que se puede aplicar esta técnica. Uno de los modelos de clustering más ampliamente utilizados está relacionado con el conjunto de problemas centerbased. Este conjunto de problemas es uno de los más recientemente estudiados debido a su eficiencia con grandes cantidades de datos. En general, un problema de este tipo busca particionar el conjunto inicial de elementos tomando como base algunos elementos centrales. Con el objetivo de mejorar las técnicas actuales en esta rama; la presente investigación desarrolla y propone un nuevo algoritmo de clustering, denominado el algoritmo SSO-C. La metodología seguida para desarrollar el algoritmo consistió en la optimización de una función multiobjetivo que relaciona dos problemas formalmente definidos con el propósito de garantizar la robustez de la solución encontrada. Como búsqueda local para valores iniciales, se tomó soluciones con un cierto factor de aproximación para un problema de optimización combinatoria relacionado, el problema k-center. En la investigación también se desarrolla y propone un segundo algoritmo de clustering, denominado el algoritmo Emax. Este segundo algoritmo es derivado del caso más robusto de la función multiobjetivo. La convergencia del algoritmo Emax es demostrada. Para efectos de comparación, se tomaron los algoritmos k-means y SSO. El primero es uno de los algoritmo más utilizados para hacer clustering, y el segundo es una adaptación delalgoritmo de optimización Social Spider Optimization para clustering; ambospertenecientes al modelo center-based. Se compararon los algoritmos mencionados junto con los propuestos (SSO-C y Emax) tomando un conjunto de 6 conjuntos de datos sintéticamente generados y 7 del mundo real tomados de la literatura. Los experimentos muestran con significación estadística que los algoritmos SSO-C y Emax dan los mejores resultados entre los algoritmos comparados. Se espera que los algoritmos propuestos generen contribuciones significativas para estado del arte.";2019
Universidad Nacional de San Antonio Abad del Cusco;Conversor de voz a texto para el idioma quechua usando la herramienta de reconocimiento de voz KALDI y una red neuronal profunda;Churata Urtado, Ruth Mery;Ingeniero Informático y de Sistemas;Carbajal Luna, Julio Cesar;El conjunto de variaciones en la pronunciación (acentos, velocidad, entonación) que son consecuencia de las variaciones en género, edad y localidad de los locutores, afectan en gran medida en la precisión de un conversor de voz a texto. Es por ello que, en esta tesis se describe la construcción de un conversor de voz a texto de habla continua con un gran vocabulario (LVCSR-Large Vocabulary continuos Speech Recognition) e independiente del locutor, para el idioma Quechua en su variación dialéctica Cusco-Qollao, basado en la herramienta Kaldi y la arquitectura de una Red Neuronal Profunda como clasificador de fonemas dentro del modelo acústico, para lo cual fue necesario la construcción del corpus de voz balanceada en género, a partir de grabaciones hechas a frases inmersas en distintos fuentes textuales, llegando a obtener un total de 18 horas de audio en Quechua. De igual forma, se realizó la construcción de los distintos recursos de voz (Diccionario fonético, fonemas y grandes colecciones de texto) necesarios para la construcción del modelo acústico y de lenguaje. Una vez construido todos los recursos de voz, se continua con el proceso de entrenamiento del modelo acústico basado en un modelo de Red Neuronal Profunda y el modelo Oculto de Markov (Deep Neural Network (DNN)-Hidden Markov Model (HMM)), del mismo modo, el modelo de lenguaje es basado en un modelo de 3-grams. Finalmente, una vez concluido el proceso de entrenamiento, se realiza el proceso de prueba o reconocimiento basado en un conjunto de experimentos con el fin de obtener valores óptimos para los parámetros de la arquitectura DNN, es así que se llegó a obtener una precisión de 59.20%, con la tasa de aprendizaje igual a 0.002, numero de nodos internos igual a 512 y el número de capas internas igual a 3 como parte de los parámetros de la arquitectura DNN dentro del modelo acústico, lo cual es bastante aceptable en comparación a investigaciones con una cantidad de recursos de voz similares.;2019
Universidad Nacional de San Antonio Abad del Cusco;Diseño e implementación de una plataforma IoT para la gestión de los controladores semafóricos en la ciudad del Cusco;Huallpamaita Quispe, José Carlos;Ingeniero Informático y de Sistemas;Pillco Quispe, José Mauro;"En la actualidad, la ciudad del Cusco se enfrenta a la rápida expansión demográfica de la zona urbana y una creciente demanda turística, lo cual, contribuye al aumento de vehículos del parque automotor, agravando los problemas en el ordenamiento vehicular y la falta de sincronización inmediata de los semáforos, genera malestar entre los peatones y usuarios vehiculares por el impedimento de llegar a sus destinos de manera oportuna. Dicha dificultad, implica hacer necesaria la implementación y optimización de los mecanismos que permitan realizar una mejor regulación de la circulación de vehículos, bicicletas y peatones. La presente tesis propone el diseño e implementación de una plataforma de software en base a los conceptos de IoT (Internet of Things o Internet de las cosas), capaz de gestionar en tiempo real la configuración las fases, horarios, ubicación, envío de configuración especial, sincronización de fecha e información de cada intersección; además de permitir la visualización del estado de cada controlador semafórico conectado por parte del personal operario. Los controladores semafóricos quedarían bajo administración de la Municipalidad Provincial del Cusco logrando interactuar, determinar, predecir y actuar en función del contexto de los datos recolectados; para ello se planteó diseñar e implementar una arquitectura que permita el flujo de datos bidireccional en dos fases; la primera con mecanismos que permita a cualquier controlador semafórico ya sea propio o de terceros que cumplan con las especificaciones del protocolo de comunicación MQTT, conectarse y enviar datos, cifrados mediante el protocolo TLS, hacia un servidor de red, mientras que la segunda fase empezará en la recepción de datos por parte servidor de red o bróker (al que llamaremos MQTTServer implementado con Mosca-MQTT en base a Node.js), a partir de este punto se realizará dos procesos en paralelo que completan el flujo de datos de la arquitectura planteada.";2018
Universidad Nacional de San Antonio Abad del Cusco;Arquitectura de interpretación de expresiones comunes de la lengua de señas del Perú al idioma español;Huallpa Vargas, Yuri Vladimir;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;La lengua de señas se percibe a través de la vista y requiere el uso de la cabeza, cuello, torso y brazos para transmitir información bajo un espacio temporal. Como cualquier otra lengua el LSP está conformado por una sintaxis, gramática y léxico diferentes del idioma oficial. El 2003 se propuso la iniciativa de educación inclusiva para personas sordas, pero no tuvo un efecto, posteriormente el ministerio de educación MINEDU, cambio el panorama y la ley 29535 dio su reconocimiento a la lengua de señas para la investigación, difusión y enseñanza para personas sordas por intérpretes acreditados. Sin embargo actualmente el LSP se encuentra dentro de las lenguas minoritarias del Perú según la Dirección General de Educación Básica Especial las personas con discapacidad auditiva se ven en la necesidad de aprender esta lengua para interactuar en la sociedad a diferencia del resto de personas que no sufren de esta discapacidad y no tienen la necesidad de aprender esta lengua, por lo que se crea una barrera en la comunicación, pese a las legislaciones del estado es muy común ver la indiferencia a esta comunidad, ya sea voluntaria o involuntariamente. Mediante técnicas de Deep Learning1 se facilita la interpretación del LSP y con una mejora en la tasa de precisi´on2 frente a modelos similares, se construye un traductor unidireccional que permita captar las señas de una persona con un dispositivo e interpretarlas en nuestro idioma. Por otro lado, se genera un dataset de vıdeos de 10 señas almacenados en 100 frames aproximadamente cada uno. El modelo de solución alimenta a la arquitectura con datos generados por un sensor Kinect, el sensor es capaz de generar un video compuesto por tres tipos de datos: frames RGB, Depth3 y Skeleton4, los datos son agrupados según el modelo para extraer las características de cada frame y posteriormente alimentan la parte recurrente encargada de la traducción. Finalmente, nuestro modelo propuesto obtuvo una tasa de exactitud de 99.23 %, una tasa muy aceptable que contribuirá a futuros trabajos dentro de este campo.;2019
Universidad Nacional de San Antonio Abad del Cusco;Propuesta de implementación para la restructuración orgánica de la Dirección de Sistemas de Información de la UNSAAC;Arizabal Vera, Moises Manuel;Ingeniero Informático y de Sistemas;Palomino Olivera, Emilio;La presente tesis tiene el objetivo de elaborar una propuesta de implementación para la restructuración orgánica de la Dirección de Sistemas de Información de la UNSAAC, con el fin de mejorar la calidad de los servicios de TI que se prestan en la UNSAAC, enfocado en la optimización de tiempo en atención de incidentes y requerimientos a través de la especialización de recursos humanos, incorporación de actividades de TI reguladas por el estado incluyendo el control interno para el perfeccionamiento de procesos. Se presentan cambios en la estructura de la Dirección de Tecnologías de la Información (actual Dirección de Sistemas de Información) como la creación de las Unidades Funcionales de: Infraestructura Tecnológica, Sistemas de Información, Soporte y Operación de Infraestructura Tecnológica, Gobierno de Tecnológicas de la Información y Seguridad de la Información, todos estos cambios se basan en el marco de trabajo propuesto por la Agenda Digital Peruana 2.0.;2019
Universidad Nacional de San Antonio Abad del Cusco;Aplicación de técnicas de minería de datos para identificación de patrones de comportamiento de las variables de proceso de generación y distribución de energía eléctrica, para la empresa Egemsa;Lavilla Alvarez,Vanesa;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"La revolución digital ha permitido que la captura de datos sea fácil, cada momento gran cantidad de datos son recogidos y almacenados en bases de datos a cada instante, y las herramientas tradicionales no son las adecuadas para procesarlas. La Minera de Datos (Data Mining) es un conjunto de técnicas y tecnologías que permiten explorar grandes bases de datos, de manera automática o semiautomática, con el objetivo de extraer conocimiento útil y comprensible. En el momento que se le atribuye algún significado a los datos estos pasan a convertirse en información. Las series temporales o series de tiempo es una colección de observaciones de una variable recogidas secuencialmente en el tiempo. La Minera de Datos Temporal (Temporal Data Mining, TDM), es la Minera de Datos para series temporales, que está compuesta por métodos que son capaces de caracterizar series temporales con distintas características fuera de los tradicionales. La Empresa de Generación Eléctrica Machupicchu S.A. (EGEMSA), a través del Sistema de Supervisión, Control y Adquisición de Datos (SCADA) va generando gran cantidad de datos y estos son almacenados en su servidor histórico, estas se almacenan por un tiempo aproximado de 3 meses y luego se eliminan, los datos relevantes se guardan en cuaderno de registro de eventos o en hojas de Excel. El sistema SCADA recibe las señales de los distintos sensores y medidores de campo (voltímetros, capacimetros, amperímetros, medidores de caudal, sensores de temperatura), a estas señales las denominaremos Variables de proceso de generación y distribución de energía eléctrica. La presente investigación busco primero extraer las variables de proceso de forma segura sin vulnerar la seguridad de la red SCADA; segundo, se implementó una Base de Datos Histórica para las variables de proceso de generación y distribución; tercero, se aplicó Técnicas de Minera de Datos Temporales (TDM) y expresiones regulares para encontrar características y patrones de comportamiento; cuarto, se aplicó clustering (técnica descriptiva de DM) con el _n de ayudar a interpretar con ayuda de la estadística descriptiva los patrones; y por último se entregó los resultados a la empresa para la toma de decisiones frente a eventualidades y planificación de mantenimientos preventivos. Para el trabajo de investigación, se utilizó la metodología CRISP-DM, ya que es un método muy utilizado y que nos permitió la flexibilidad de avanzar o retroceder en sus distintas fases";2019
Universidad Nacional de San Antonio Abad del Cusco;Software multiplataforma para restaurantes utilizando tecnologías híbridas Node.Js, Electron.Js y React Native;Muñiz Huamán,Omar Alexander;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;En la actualidad existen diversas maneras de desarrollar software, con diferentes lenguajes de programación, en diferentes plataformas (escritorio, web y móvil), algunas tecnologías muchos más versátiles que otras en relación a la facilidad de aprendizaje, a la sintaxis simple del lenguaje, entre otros aspectos. Esto hace que el proceso de desarrollo de software sea complejo o simple dependiendo de la tecnología que se quiera usar. En muchos casos se requiere desarrollar software donde se vinculan plataformas no solo en un entorno de escritorio sino también un entorno web y móvil, es por ello que bajo esa premisa surge las tecnologías híbridas que orientan el proceso de desarrollo de software a una actividad mucho menos compleja ayudando en la reducción de los tiempos de desarrollo, depuración de errores, soporte amplio de librerías para ejecutar cualquier proceso entre otros aspectos. Un caso práctico para observar la funcionalidad, potencialidad y robustez de las aplicaciones híbridas está planteado en los sistemas para restaurantes en donde interactúan varias plataformas y por lo cual las tecnologías híbridas encajan de manera perfecta para este caso en particular. Por una parte, para el software de restaurantes, es necesario un sistema de escritorio para la parte administrativa, en donde se tiene un controlador principal que es una aplicación que servirá para el mantenimiento de los procesos del restaurante tales como el registro de productos, registro de sucursales, registro de mesas, actualizaciones de los registros, generación de documentos (recibos, tickets), control de peticiones entre otros que engloban en si la parte administrativa. Junto con ello la misma funcionalidad del sistema de escritorio, debe estar desplegado hacia el entorno web, de tal manera que los administradores del restaurante puedan tener un control de todos los movimientos de entrada y salida que genera el restaurante sin necesidad de estar presente físicamente en el lugar donde se encuentra instalado el software.Por último, para automatizar la toma de pedido a los comensales es necesario disponer de una aplicación móvil que hará el proceso de registro de un pedido el cual involucra la cantidad de platillos pedidos por comensal, el precio de cada platillo, combinaciones y fusiones de platillos, generación de comandas con recibos físicos para la cocina, bar y otras secciones del restaurante. Por todos los puntos mencionados el modelo de negocio de un restaurante es complejo a la hora del desarrollo puesto que se debería En la actualidad existen diversas maneras de desarrollar software, con diferentes lenguajes de programación, en diferentes plataformas (escritorio, web y móvil), algunas tecnologías muchos más versátiles que otras en relación a la facilidad de aprendizaje, a la sintaxis simple del lenguaje, entre otros aspectos. Esto hace que el proceso de desarrollo de software sea complejo o simple dependiendo de la tecnología que se quiera usar. En muchos casos se requiere desarrollar software donde se vinculan plataformas no solo en un entorno de escritorio sino también un entorno web y móvil, es por ello que bajo esa premisa surge las tecnologías híbridas que orientan el proceso de desarrollo de software a una actividad mucho menos compleja ayudando en la reducción de los tiempos de desarrollo, depuración de errores, soporte amplio de librerías para ejecutar cualquier proceso entre otros aspectos. Un caso práctico para observar la funcionalidad, potencialidad y robustez de las aplicaciones híbridas está planteado en los sistemas para restaurantes en donde interactúan varias plataformas y por lo cual las tecnologías híbridas encajan de manera perfecta para este caso en particular. Por una parte, para el software de restaurantes, es necesario un sistema de escritorio para la parte administrativa, en donde se tiene un controlador principal que es una aplicación que servirá para el mantenimiento de los procesos del restaurante tales como el registro de productos, registro de sucursales, registro de mesas, actualizaciones de los registros, generación de documentos (recibos, tickets), control de peticiones entre otros que engloban en si la parte administrativa. Junto con ello la misma funcionalidad del sistema de escritorio, debe estar desplegado hacia el entorno web, de tal manera que los administradores del restaurante puedan tener un control de todos los movimientos de entrada y salida que genera el restaurante sin necesidad de estar presente físicamente en el lugar donde se encuentra instalado el software. Por último, para automatizar la toma de pedido a los comensales es necesario disponer de una aplicación móvil que hará el proceso de registro de un pedido el cual involucra la cantidad de platillos pedidos por comensal, el precio de cada platillo, combinaciones y fusiones de platillos, generación de comandas con recibos físicos para la cocina, bar y otras secciones del restaurante. Por todos los puntos mencionados el modelo de negocio de un restaurante es complejo a la hora del desarrollo puesto que se debería;2019
Universidad Nacional de San Antonio Abad del Cusco;Desarrollo de un aplicativo para reportar incidentes en el distrito del Cusco para la oficina de catastro de la Municipalidad Provincial del Cusco;Ergueta Huanca, Jorge Edison;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;El presente trabajo de tesis busca desarrollar un aplicativo móvil cuyo propósito es generar un apoyo a la oficina de catastro y por ende a la Municipalidad del Cusco, mediante el almacenamiento de reportes de incidentes, que a su vez apoyados con la retroalimentación de los ciudadanos sirva para un análisis de datos temporales o como recolección de quejas de ciudadanos. La metodología del desarrollo del proyecto es la explicativa y junto a las tecnologías actuales se busca realizar un aplicativo cuyas características no solo satisfagan al usuario final o el ciudadano, sino también analizar ciertos parámetros para el valor de dichos reportes, los cuales buscan una mejor en cuanto a reportes de incidentes se trata. El desarrollo metodológico para este aplicativo está compuesto por el marco de trabajo SCRUM, este marco esta acoplado con la metodología UCD los cuales mezclan parámetros iterativos para corregir errores y sobrepasarlos a medida que se hace las verificaciones de la mano con el usuario final, esto no solo ayudara en la parte de realizar un aplicativo móvil a la medida del usuario, sino que también prioriza la usabilidad y funcionabilidad del mismo aplicativo. La información de los reportes de incidentes será almacenada en la base de datos del mismo servidor de la Municipalidad del cusco para la oficina de catastro, esta información, mediante las responsabilidades de la misma oficina será distribuidas a las gerencias correspondientes para el trato de los incidentes en caso sean reales o serios. El aplicativo móvil deberá apoyar a la oficina de catastro en el almacenamiento de la información distinguiendo del tipo de incidente y su ubicación, estos datos podrán determinar tomas de decisiones en torno a zonas o lugares específicos de acuerdo al reporte. Es claro que las prioridades de los reportes son relacionadas con los catastrales, sean de edificaciones o alteraciones de patrimonio, pero fundamentado por la estructura orgánica del municipio es que se ve por conveniente aceptar los reportes de los distintos tipos de incidentes los cuales servirán para la Municipalidad como el conjunto de gerencias que la conforman.;2019
Universidad Nacional de San Antonio Abad del Cusco;Diseño e implementación de una base de datos federada;Lezama Ttito, Gorky;Ingeniero Informático y de Sistemas;Rozas Huacho, Javier Arturo;"La información presente en algunas organizaciones generalmente se encuentra alojada en diferentes fuentes de datos, así como administradas por diferentes sistemas gestores de bases de datos, debido a que cada uno de ellos ofrece diversas ventajas en ciertos aspectos sobre el control de la información de acuerdo a las necesidades de cada organización. Las dificultades se presentan en el momento de acceder de forma integral a dicha información, que es manejada por cada gestor de base de datos, manteniendo la consistencia de la información de cada fuente de datos. Una base de datos federada es un sistema donde las bases de datos que las integran conforman un ente virtual único y funcional, que brinda un servicio homogéneo y transparente al usuario, manteniendo principalmente la autonomía y funcionalidades propias de cada base de datos de la federación; proponiéndose aquí mostrar la integración del acceso a todas las bases de datos componentes necesarias según sea el tipo de información que se requiera, mediante las bases de datos federadas; de las cuales existen muchas implementaciones, desde las arquitecturas federadas de cinco niveles de Sheth y Larson , la arquitectura federada de tres niveles de ANSI/SPARC, y basados en ellos actualmente: IBM Fedérat Server, SQL Server, Oracle y otros, que ofrecen diversas soluciones al problema del acceso federado a la información. En base a esta documentación, se construye un prototipo de la implementación de una base de datos federada con componentes heterogéneos, utilizando la metodología PUDS (Proceso Unificado de Desarrollo de Software). Y, como resultado de este diseño e implementación de una base de datos federada para la integración del acceso a la información de diferentes gestores de bases de datos, se evita al usuario lidiar con las características particulares de cada gestor de bases de datos para acceder a la información requerida. Palabras Clave: Bases de Datos, Bases de Datos Federadas, Sistema de Bases de Datos Federadas, Base de Datos Componentes, Acceso Integrado a la Información.";2019
Universidad Nacional de San Antonio Abad del Cusco;Obtención de fotogramas clave en videos de tránsito vehicular en la ciudad del Cusco utilizando K-Means en GPU;Ccapatinta Loayza, Kevin Percy;Ingeniero Informático y de Sistemas;Palma Ttito, Luis Beltran;El acúmulo de videos de tránsito en la ciudad del Cusco ha ido incrementándose en los últimos años, debido al incremento en la instalación de cámaras de video para contribuir a mitigar los problemas de seguridad ciudadana. Dentro de las aplicaciones del procesamiento de video, una de las más importantes es el resumen de videos, que se obtienen a través de los fotogramas clave, y este es el énfasis de este trabajo, implementando un prototipo para mejorar el almacenamiento de información bajo el contexto de videos de tránsito vehicular en la ciudad del Cusco. Dada la gran variedad de técnicas existentes para la obtención de fotogramas clave, se opta por utilizar la comparación global entre fotogramas por ser una de las técnicas más utilizadas y que menores recursos requiere debido al preprocesamiento en la extracción de saliencia utilizando algoritmos de Redes Neuronales y K-Means en GPU, se reconoce que Redes Neuronales es ampliamente utilizado y se evaluará el método frente a K-Means, desarrollando y comparando ambas técnicas mediante Precision-Recall Curves y Mean Absolute Error. Su importancia se centra en medir la eficiencia de dichos algoritmos, para ofrecer una visión amplia de acuerdo a las aplicaciones que se pueda implementar en base a lo desarrollado.;2019
Universidad Nacional de San Antonio Abad del Cusco;Técnica de gamificación aplicada al desarrollo de una plataforma de avisos clasificados para la región del Cusco;Hermoza Salcedo, Fahed;Ingeniero Informático y de Sistemas;Palomino Olivera, Emilio;El presente trabajo de investigación aplica técnica de gamificación al desarrollo de la plataforma de avisos clasificados, cuyo propósito es la administración y visualización de avisos clasificados teniendo como núcleo esencial la fidelización de los usuarios. El desarrollo metodológico del proyecto se basa en el método descriptivo. Al cual se recurre para organizar, resumir, analizar y seleccionar los datos con el fin de tener una idea de la situación actual. Para el desarrollo de la plataforma se emplea las especificaciones de la Metodología Ágil Scrum con Kanban. Los avisos son ingresados y cargados a través de una aplicación web construidos en GWT. Dicha información se enviará a un servidor de aplicaciones WildFly haciendo uso de los servicios web REST. En el servidor se procesa y almacena la información en la base de datos MongoDB. Cualquier usuario que tenga descargada la aplicación móvil podrá consultar las diferentes categorías de avisos disponibles. La aplicación móvil es gamificado utilizando el Framework Octalysis obteniendo un diseño de gamificación usado para la construcción de la app móvil. Finalmente se evaluaron las técnicas de gamificación utilizando dos cuestionario, el primero “System Usability Scale” y el segundo cuestionario del sistema gamificación mediante los cuales se evaluaron la usabilidad (efectividad, eficiencia y satisfacción), aceptabilidad, frecuencia y recomendación de la aplicación móvil. Así mismo se obtuvieron resultados óptimos de las pruebas realizadas. El resultado de la investigación es una plataforma de avisos clasificados gamificado enfocado en la región del Cusco, contribuyendo al estudio de la gamificación y su implementación en la plataforma de software.;2019
Universidad Nacional de San Antonio Abad del Cusco;Optimización de métodos radiales de exploración de datos multidimensionales a través de algoritmos de aprendizaje máquina;García Zanabria, Germain;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;El descubrimiento de patrones en conjuntos de datos despierta gran interés en la comunidad de investigadores. Específicamente, en el manejo de datos multidimensionales o datos de alta dimensión se han realizado grandes avances. Sin embargo, todavía existen ciertas limitaciones como: costo computacional, falta de percepción visual y la interacción con el usuario  que impiden que la tarea de extracción de patrones y agrupamientos sea simple y eficiente. El grupo de técnicas que mitigan estos problemas son los denominados Técnicas de Visualización Radial (Star Coordinates, Radviz, Barycentric Coordinates), los cuales son capaces de revelar patrones y grupos de datos multidimensionales mientras muestran el impacto de los atributos en la formación de la representación de los datos. A pesar de su utilidad, las  técnicas de exploración radial tienen ciertos inconvenientes que impiden su uso en varios escenarios. Por ejemplo, cuando el número de dimensiones de los datos es realmente alto, las visualizaciones resultantes se vuelven desordenadas y sobrecargadas, lo que dificulta el análisis de la importancia de los atributos en la formación de grupos y/o patrones. En este trabajo de investigación se optimiza las técnicas de visualización radial aprovechando sus  ventajas (interacción y bajo costo computacional) y fortaleciendo sus deficiencias (manejo de datos con un numero alto de dimensiones) en el análisis de datos multidimensionales. La optimización de estas técnicas se cimienta en el agrupamiento (similaridad de atributos) y reordenamiento de atributos (optimización de ubicación) con el _n de mitigar la distorsión  visual. El agrupamiento y reordenamiento se puede realizar de forma automática, así como de forma interactiva, lo que permite que el usuario pueda analizar a un mas el impacto de los atributos en la visualización radial. La eficacia de los enfoques presentados se muestran a través de una serie de experimentos y estudios de caso, los cuales evidencian utilidad de la propuesta.;2017
Universidad Nacional de San Antonio Abad del Cusco;Clasificación y reconocimiento de gestos estáticos de la mano basado en el alfabeto dactilológico de la lengua de señas del Perú aplicando redes profundas bajo características invariantes;Flores Campana, Jose Luis;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"El reconocimiento de gestos de las manos es un área de investigación muy activa en visión por computador, interacción hombre-computadora (HCI), aprendizaje automático y robótica, principalmente en el lenguaje de señas, ayuda en el proceso de traducción e integración de personas con discapacidad auditiva, así como su enseñanza a la población no auditiva. El presente trabajo está enfocado en clasificar y reconocer los 24 gestos estáticos de la mano basados en el alfabeto dactilológico de la lengua de señas del Perú (LSP), no se hará uso de los gestos dinámicos debido a que el enfoque del trabajo es el uso de las redes profundas para imágenes. Sin embargo, en los últimos años se busca que clasifiquen y reconozcan estos gestos adecuadamente ante invariaciones de escala, rotación y traslación; y sean robustas ante ruido y cambios de iluminación. El objetivo es desarrollar una arquitectura de una Convolutional Neural Network (CNN) y otra de Stacked Denoising Autoencoder (SDAE) para clasificar el conjunto de 24 gestos estáticos de la mano de la LSP obtenidos de la base de datos desarrollada. Para el desarrollo del proyecto de investigación se usó un tipo de investigación explorativa, teórica y aplicativa. Se desarrolló una base de datos basado en el alfabeto dactilológico de la LSP, y se propuso un algoritmo efectivo para detectar la región que contiene el gesto de la mano, el algoritmo incorpora una etapa de pre procesamiento y segmentación. Hoy en día aprendizaje profundo ha dado paso a grandes avances en los últimos años, sobre todo en los campos de reconocimiento de voz e imágenes por lo tanto se hizo uso de redes profundas CNN y SDAE como extractores y clasificadores, además de extraer muy bien las características de una imagen ante invariaciones de escala, traslación y rotación, son capaces de aprender la compleja tarea de clasificación de gestos de las manos con menores tasas de error. Se usó el GPU para acelerar el entrenamiento de las redes profundas y se comparó los resultados de precisión y error obtenido entre las dos arquitecturas de red profunda diseñadas (CNN y SDAE) con técnicas usuales de extracción y clasificación de machine learning. Este proyecto de investigación sirve de ayuda para muchos investigadores dentro de la línea de investigación, como también en el desarrollo de futuros proyectos relacionados al procesamiento digital de imágenes, reconocimiento de gestos de la mano y aprendizaje profundo.";2017
Universidad Nacional de San Antonio Abad del Cusco;Análisis comparativa y diseño de una red 4G LTE en la provincia del Cusco empleando software de radioenlace;Rios Quispe, Ronald;Ingeniero Informático y de Sistemas;Peñaloza Figueroa, Manuel Aurelio;"El trabajo de tesis consiste en el análisis, comparativa y diseño de Red 4G LTE en la provincia del Cusco empleando software de radioenlace; para desarrollar la simulación de la red, previamente antes de realizar la simulación se hace un estudio en detalle de las diversas generación móviles, en la simulación se emplearan varios programas. Con el desarrollo de la simulación se quiere que sea una herramienta de apoyo técnico para personas o instituciones que deseen realizar futuros diseños de simulación de las redes 4G LTE, que pudieran realizarse en las diversas provincias o regiones del país y a su vez tener la información teórica de la simulación como cobertura, rendimiento y eficiencia de la red y poder contrastarlos con los ofrecidos por los operadores de esta tecnología móvil en la zonas donde se quiera la implementación de esta tecnología.";2019
Universidad Nacional de San Antonio Abad del Cusco;Evaluación de técnicas de aprendizaje de máquina para la identificación de imágenes de edificios históricos de la ciudad del Cusco basado en Bag-Of-Words y redes neuronales convolucionales;Farfan Escobedo, Jeanfranco David;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"Actualmente existen muchas técnicas de aprendizaje de máquina efectivas durante la tarea de clasificación. Sin embargo, existe la necesidad de identificar que técnica destaca por encima del resto. Por consiguiente, es necesario evaluar un conjunto de técnicas de aprendizaje de máquina en un escenario desafiante. En particular, el escenario seleccionado en este trabajo corresponde al reconocimiento de edificios a partir de imágenes; el reconocimiento de edificios es una tarea difícil, ya que las imágenes pueden tomarse desde diferentes ángulos, bajo diferentes condiciones de iluminación y un desafío adicional es diferenciar edificios visualmente similares (por ejemplo, imágenes de iglesias). La mayoría de métodos de reconocimiento de edificios utilizan descriptores locales de la imagen para la extracción de características (es decir, luego de aplicar SIFT o SURF, se aplica un clasificador). No obstante, este método presenta una precisión limitada. Por lo tanto, es necesario evaluar técnicas de aprendizaje de máquina que resuelvan este tipo de problemas de una manera más precisa. Se propone evaluar técnicas de aprendizaje de máquina como Support Vector Machine (SVM), Random Forest (RF), Neuronal Network (NN) y K-Nearest Neighbod (KNN), a partir de métodos basados en Bag-of-Words y Redes Neuronales Convolucionales, para obtener vectores de características efectivos y realizar un reconocimiento de edificios preciso. Por último, se espera que los resultados permitan una mejor comprensión de las técnicas de aprendizaje de máquina aplicado al problema del reconocimiento de edificios de la ciudad del Cusco.";2018
Universidad Nacional de San Antonio Abad del Cusco;Análisis de métodos de visión computacional y Machine Learning para la clasificación de imágenes de variedades de papa nativa;Cardoso Cusihuallpa, Carla Doris;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"La poca difusión de las diversas variedades de papas nativas existentes en el mercado repercute en el consumo limitado. Si bien es cierto que, existen diversas investigaciones sobre este tubérculo en distintas áreas como: la Agricultura, Genética, Salud, entre otros. El área de las Ciencias de la Computación también forma parte de ello, específicamente en el área de Visión Computacional, que ha tomado importancia en el control de calidad y/o enfermedades de la papa, mas no investigaciones para clasificar automáticamente papas nativas, ni investigaciones sobre cuáles son los métodos más apropiados de visión computacional y machine learning para el mismo fin, por ser un producto propio de los Andes del Perú. En el desarrollo del proyecto se analiza los métodos de visión computacional y Machine Learning para clasificar variedades de papas nativas. Para la clasificación manual de las variedades de papas nativas, se utiliza características externas de color, forma y textura. Se propone un extractor que contempla dichas características. Se obtiene características de color en los espacios: RGB, CMY, HSV, HSI, YCbCr, YIQ, LUV y Colores Oponentes. Se obtiene características de forma con los descriptores de Fourier Polar Bidimensionales, por ser invariantes a la rotación, traslación y escalamiento, sin perder la información de la imagen. Se obtiene características de textura realizando un análisis estadístico utilizando la matriz de coocurrencia, por ser el método más popular para extraer información importante de la textura. También se estudia los métodos de extracción de características Scale Invariant Feature Transform y Speed Up Robust Features; proponiéndose mejorar su rendimiento, al incluir el color en sus descriptores. Dentro de los métodos de Machine Learning se estudia los clasificadores Support Vector Machine y Random Forest. Se demuestra que al incluir la característica de color en los métodos Scale Invariant Feature Transform y Speed Up Robust Features muestran una mejor precisión que los métodos sin la característica de color. El método con mejor tasa de aciertos para la clasificación de papa nativa es el extractor propuesto con el clasificador Random Forest, demostrando que el extractor propuesto es apropiado para clasificar las variedades de papa nativa.";2018
Universidad Nacional de San Antonio Abad del Cusco;Desarrollo de una arquitectura de red neuronal convolucional como un modelo del proceso cerebral humano para la clasificación de expresiones faciales;Flores Atauchi, Paul Dany;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;Las expresiones faciales son un medio de comunicación no verbal que muestran las emociones de una persona, estas expresiones ayudan a transmitir información en las interacciones inter personales y facilitan el entendimiento del significado del lenguaje hablado. Por lo que se considera que poder clasificar la expresión de un rostro sería una gran fuente de información para una posterior utilización. El objetivo del presente proyecto es modelar el proceso cerebral humano para clasificar imágenes de expresiones faciales por medio de una de las técnicas de Deep Learning, logrando así que una máquina sea capaz de aprender de imágenes de expresiones faciales suministradas de ejemplo (datos de entrenamiento) con el objetivo de poder clasificar ejemplos futuros sin ningún tipo de intervención humana en el proceso. En la actualidad, gracias a las Redes Neuronales Convolucionales, se están logrando buenos resultados en la clasificación de imágenes, detección de objetos, comprensión de escena, en comparación con técnicas convencionales, por lo cual en este proyecto se usó la arquitectura de una Red Neuronal Convolucional para clasificar las expresiones faciales, clasificándolas en 6 categorías: enojo, miedo, alegría, tristeza, sorpresa y neutro. Este trabajo aporta a una mejor comprensión en las redes neuronales Convolucionales aplicada al reconocimiento de expresiones faciales e imágenes en general, también ayudara en el desarrollo de futuros proyecto que necesiten del reconocimiento de expresiones faciales, como: estudio de marketing, interacción hombre-máquina, psicología, análisis educativo y otros.;2018
Universidad Nacional de San Antonio Abad del Cusco;Construcción de un prototipo web para la traducción de español a quechua pentavocálico mediante analizador sintáctico;Tijero Fuentes, Rafael;Ingeniero Informático y de Sistemas;Pillco Quispe, Jose Mauro;"En la presente tesis se ha desarrollado la construcción de una aplicación para la traducción de texto del idioma Español al idioma Quechua Pentavocálico en plataforma web, construyendo un analizador sintáctico que usa las metodologías de traducción automática basada en reglas. Por lo que, se ha realizado un análisis de las reglas gramaticales de los idiomas Español y Quechua Pentavocálico. Después, se construyeron reglas de equivalencia y plantillas de traducción automática. Luego, se ha construido el diccionario de palabras tanto para el idioma Español y Quechua Pentavocálico; se recopilaron las palabras del diccionario de la Real Academia de Lengua Quechua y se clasificaron por las reglas gramaticales de cada palabra. Seguidamente, se construyó el corpus lingüístico con oraciones del idioma Español y su traducción respectiva en el idioma Quechua Pentavocálico. Posteriormente, se construyó un analizador sintáctico que puede realizar el análisis sintáctico del texto de entrada, reconocer sus componentes e identificar sus respectivos elementos, y el traductor automático que se encarga de buscar la traducción de cada elemento analizado en el paso anterior, y por último, reordena los elementos a la estructura SOV del Quechua Pentavocálico. El desarrollo de esta herramienta, el uso y las futuras mejoras, nos permitirá entender las metodologías de traducción automática y será de utilidad en la enseñanza de la gramática, tanto para el idioma Español y el idioma Quechua. A su vez, formará parte de las herramientas tecnológicas o materia de investigación para las tecnologías referentes al idioma Quechua.";2018
Universidad Nacional de San Antonio Abad del Cusco;Uso de un algoritmo de realce de características como apoyo para un clasificador de redes neuronales convolucionales en imágenes de libélulas del género rhionaeschna;Andrade Cari, Jose Guillermo;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"En el estudio de diversas áreas de la ciencia los especialistas utilizan técnicas de clasificación que les permiten estandarizar conocimientos a nivel mundial. En la entomología, que es el estudio de los insectos, la gran cantidad de especies animales en el planeta tierra plantea una clara dificultad en el momento de compartir información; para solucionar este inconveniente, los biólogos utilizan la sistemática o taxonomia, con el fin de clasificar organismos vivos según sus características fenotípicas en reinos, filos, clases, órdenes, familias, géneros y especies. El diagnóstico visual de estas características fenotípicas es la base de esta investigación, los entomólogos utilizan una serie de claves físicas que permite distinguir a las especies según su apariencia, formas, colores y tamaños. Para realizar este proceso de manera más rápida y automatizada existen muchas herramientas de clasificación, actualmente se están desarrollando algoritmos de clasificación de imágenes o chasquido de saltamontes (Guevara, 2008), así como reconocimiento de artrópodos (Siti N. A. Hassan, 2014). Para el desarrollo de una herramienta de diagnóstico visual de fenotipos de especies, primero necesitamos crear un dataset de imágenes tomadas por diversas cámaras y ángulos de las muestras a estudiar (dos especies de libélulas del género Rhionaeschna), posteriormente tenemos que preprocesar estas imágenes para obtener un buen resultado en la clasificación, teniendo en cuenta que el algoritmo debe ser aplicado en computadoras económicas o dispositivos móviles de bajo costo, por lo tanto se debe minimizar el uso de recursos. Luego, se hace uso de un clasificador que en este caso estará basado en la teoría de Redes Neuronales Convolucionales, éste, trabajará con una arquitectura de procesamiento preentrenada para reducir el costo computacional. Uniendo ambas etapas, deseamos lograr un aumento en la precisión de nuestro clasificador de RNC con el fin de obtener una herramienta que no solo brinda un bajo costo computacional, sino una precisión aceptable para una posterior implementación de un aplicativo que pueda ser usado por especialistas en cualquier parte del mundo para la detección de especies de libélulas. Se planteó la arquitectura de RNC Inception-v3 para el desarrollo de esta investigación, la cual nos brinda un clasificador pre-entrenado, que reduce el costo computacional del proyecto, también es la arquitectura con mejor desempeño y mayor taza de acierto en el mercado según la competencia de reconocimiento visual a gran escala de ImageNet del año 2014. Siendo la mejor alternativa para resolver el problema de esta investigación. El uso del método haar cascade permitió reducir las imágenes a una escala más cómoda para el clasificador al momento de realizar la categorización de especies. El clasificador haar cascade y un algoritmo de realce de características como método de pre-procesamiento de imágenes ayudó a reducir el tiempo de entrenamiento de la red neuronal.";2018
Universidad Nacional de San Antonio Abad del Cusco;Sistema de transporte inteligente (STI), para el control y monitoreo del servicio urbano en la Ciudad del Cusco;Alvarez Mamani, Edwin;Ingeniero Informático y de Sistemas;Palma Ttito, Luis Beltrán;"El desorden y la falta de herramientas apropiadas para el control, monitoreo y administración del transporte urbano, diariamente afecta a miles de usuarios que recurren a este medio para poder movilizarse. Por otra parte el proceso de control de tiempos de los autobuses se realiza de forma manual, con la ayuda de relojes mecánicos. Donde el cobrador, tiene que registrar la hora a la que pasa el autobús por cada punto de control a lo largo de su ruta. Esta actividad es muy peligrosa; porque en algunos casos el cobrador tiene que cruzar la pista en avenidas muy congestionadas. Otro problema es el tiempo excesivo de espera de un autobús en los paraderos por parte de los usuarios. Todo esto se origina a causa de no contar con información en tiempo real que ayude a regular, distribuir a los autobuses de mejor manera en su ruta y de esta forma mitigar el fenómeno de agrupamiento de los autobuses. El objetivo es desarrollar un Sistema de Transporte Inteligente (STI) que permita controlar, monitorear y administrar en tiempo real a la flota de autobuses de las empresas de transporte urbano; haciendo uso de una plataforma web y de una aplicación móvil para el control de tiempos, que interactúe de manera confiable con el sistema de control y monitoreo. Para lograr estos objetivos propuestos se diseñará un algoritmo de búsqueda y registro de tiempos de control, se diseñará una arquitectura para el STI acorde a las necesidades y normas del transporte urbano en la ciudad del Cusco, adicionalmente se diseñará un algoritmo para mostrar autobuses cercanos a un paradero, por lo tanto el usuario mediante una aplicación móvil dispondrá de información en tiempo real de la ubicación de su autobús. Con este STI se reducirá el tiempo de espera por parte de los usuarios, se tendrá un transporte urbano más ordenado, se mitigara el fenómeno de agrupamiento de los autobuses y el proceso de control de tiempo se realizará de forma automática; todo esto permitirá tener una ciudad Inteligente.";2018
Universidad Nacional de San Antonio Abad del Cusco;Plataforma web para la personalización de videojuegos educativos dirigido a docentes de segundo grado de primaria para los cursos de comunicación, personal social y ciencia y ambiente;Silva Sosa, Rosa Elaida;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"Actualmente los videojuegos representan uno de los medios de introducción a la cultura informática más directa para los niños. Los videojuegos son ampliamente criticados por su contenido ya que tienen un fuerte poder influyente en quienes lo practican; sin embargo, dejando de lado por un momento este factor negativo, su valor educacional ha sido muchas veces estudiada por psicólogos y pedagogos, quienes llegaron a diferentes conclusiones. La mayoría de estas investigaciones científicas coinciden en que los videojuegos comerciales y educativos además de ser motivacionales favorecen el desarrollo y adquisición de determinadas habilidades, competencias y estrategias. En nuestra región esta estrategia lúdica basada en videojuegos es poca o simplemente no es usada, desaprovechándose así el potencial de estos en sesiones de enseñanza-aprendizaje, a pesar de que su valor educativo ya ha sido comprobado y aceptado. Por lo expuesto, la presente tesis constituye una propuesta para los docentes de educación primaria que consiste en la implementación y aplicación de una plataforma web para la personalización de videojuegos educativos dirigido a docentes de segundo grado de primaria para las áreas curriculares de Comunicación, Personal Social y Ciencia y Ambiente. La construcción de la plataforma “Pukllay” inició con el análisis del currículo y objetivos del segundo grado de primaria, la captura de datos a través de encuestas y entrevistas a docentes, revisión de libros utilizados por los profesores encuestados, observación directa de sesiones de clase y análisis de proyectos que se tomaron como antecedentes.";2017
Universidad Nacional de San Antonio Abad del Cusco;Implementación del algoritmo de Smith - Waterman utilizando instrucciones SIMD mediante OPENMP;Condori Alagón, Héctor;Ingeniero Informático y de Sistemas;Carrasco Poblete, Edwin;El presente trabajo aborda el problema de acelerar la ejecución del algoritmo de Smith-Waterman haciendo uso de las instrucciones vectoriales disponibles en las CPU modernas. Como ejemplo de implementaciones de Smith-Waterman podemos citar a Swipe[8], que está implementada con funciones intrínsecas y secciones de ensamblador, optimizada para usar instrucciones SSE. El problema de muchas de estas implementaciones es que no son portables, además de no ser fácilmente mantenibles. Para poder ejecutarse en una arquitectura diferente, muchas veces es necesario reescribir la aplicación. La propuesta del presente trabajo es utilizar OpenMP para desarrollar una implementación portable del algoritmo de Smith-Waterman acelerada mediante instrucciones vectoriales. Utilizar OpenMP permitirá resolver el problema de la portabilidad de rendimiento para este algoritmo. Gracias al uso de OpenMP, fue posible acelerar la ejecución del algoritmo de Smith-Waterman dramáticamente con respecto a la versión que no utiliza instrucciones vectoriales, consiguiendo un rendimiento que rivaliza con una implementación vectorizada con funciones intrínsecas.;2016
Universidad Nacional de San Antonio Abad del Cusco;Uso de Técnicas de machine learning para la clasificación de imágenes de danzas típicas del Cusco;Quispe Condori, Edgar Rodolfo;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"Cusco es una de las ciudades del mundo con mayor presencia de danzas autóctonas. Cada año, antropólogos folkloristas encuentran más información sobre las danzas y así rescatan parte de nuestra cultura. Sólo en las festividades podemos ubicar al menos 4 danzas típicas muy comunes: Qhapaq Qolla, Qhapaq Chuncho, Negrillo, y Contradanza. Por otro lado, Cusco también es conocido como una de las ciudades más turísticas del mundo y con todo el avance tecnológico que se viene dando, ahora es más fácil tomar fotografías y así preservar diversos eventos. Por lo tanto, se cuenta con mucha información visual que no es procesada. Computacionalmente hablando, se puede lidiar con este problema mediante la clasificación automática de imágenes. La aplicación de este problema puede ser visto en diferentes áreas como Sistemas de vigilancia, sistemas de recuperación, compresión, segmentación de imágenes, y muchos otras más. La clasificación de imágenes también representa un gran desafío debido a los problemas en iluminación, rotación, escala, oclusión o variación de puntos de vista. Actualmente, los trabajos en clasificación de danzas se enfocan en videos, sin embargo, en imágenes este problema está muy poco estudiado. Los trabajos más relacionados que usan imágenes buscan clasificar eventos culturales; a diferencia de éstos, la información contextual de la imagen no juega un papel relevante como para los eventos culturales. Este trabajo busca clasificar imágenes de danzas típicas del Cusco, el problema se torna particularmente interesante debido a que además de los problemas ya mostrados, se debe trabajar sobre la figura humana. El método planteado fue dividido en dos etapas, en la primera se localiza al danzante dentro de la imagen mediante la detección de máscaras usando Histogram of Oriented Gradient y técnicas de detección de rostros, y en la segunda se realiza la clasificación mediante Bag-of-Words. El principal aporte de este trabajo es realizar un estudio del desempeño de técnicas de Machine Learning en la clasificación de imágenes de danzas, igualmente se creó un dataset con imágenes etiquetadas de las danzas de la región que fueron de interés para el trabajo. Cabe recalcar que este dataset es el primero de su tipo y que será puesto de manera abierta a la comunidad científica para aportar al estado-del-arte. Los resultados obtenidos muestran una tasa de acierto alta para éste problema.";2017
Universidad Nacional de San Antonio Abad del Cusco;Data warehousing en la gerencia de operaciones de la empresa pública de servicios de saneamiento Seda Cusco S.A.;Santos Prado, Miguel Angel;Ingeniero Informático y de Sistemas;Rozas Huacho, Javier Arturo;"En la actualidad, existen muchos sistemas con bases de datos dentro de las empresas orientadas al procesamiento de transacciones (OLTP), ignorando por completo el proceso analítico (OLAP), trayendo consigo una serie de deficiencias tanto en el análisis de satos, como en la toma de decisiones. Ese es el caso del Departamento de Mantenimiento e Instalaciones que pertenece a la Gerencia de Operaciones de la EPS SEDACUSCO. Por lo tanto, tomando en cuenta esta necesidad se presentó el siguiente proyecto de tesis, que trató principalmente de implementar un Datamart con el fin de incorporar el procesamiento analítico (OLAP) de las bases de datos y mostrar los beneficios de esta. El objetivo del trabajo fue diseñar e implementar una base de datos diseñada y estructurada principalmente para el soporte de toma de decisiones en el Departamento de Manteniemiento e Instalaciones. Se desarrolló una herramienta que asegure el acceso eficiente a los datos agrupados desde distintos orígenes; permitiendo con ello, lograr un análisis adecuado de los datos por volumen y distribuirlos por distintos filtros como fechas, ubicaciones, trabajadores, materiales, solicitudes de servicio, entre otros y dar la facilidad a la gerencia para que interprete mejor dicha información. De igual modo, el proyecto permite a la alta dirección clasificar y estudiar la información desde sus propios puntos de vista gracias al nivel de detalle considerado. Seguidamente, tomar mejores decisiones a nivel de gestión en relación a los mantenimientos e instalaciones. Finalmente la metodología de Ralph Kimball logro guiar exitosamente toda la construcción de la solución.";2016
Universidad Nacional de San Antonio Abad del Cusco;Diseño e implementación de una herramienta case para la metodología programación extrema;Polo Soto, Omar;Ingeniero Informático y de Sistemas;Alzamora Paredes, Robert Wilbert;El presente trabajo de tesis realiza el diseño e implementación de una herramienta CASE (Computer Aided Software Engineering o Ingeniería de Software asistida por computadora) para apoyar en las labores de planificación, monitoreo y documentación de un determinado equipo de trabajo que utilice la metodología ágil denominada programación extrema durante la elaboración de un determinado proyecto de desarrollo de software. Permite comprender el ciclo de vida, hacer uso de los artefactos de la metodología de manera computarizada, aplicar las prácticas de la metodología , así como integrar al equipo de trabajo según sus respectivos roles durante el desarrollo del proyecto de modo que pueda ser de gran utilidad sin entrar en contradicción con los principios establecidos en el manifiesto ágil o los valores propios de la metodología, teniendo como resultado información estadística del proyecto y documentación que sustente al mismo.;2016
Universidad Nacional de San Antonio Abad del Cusco;Implementación de un prototipo de algoritmo para buscar música por similitud de contenido de audio musical;Enciso Valencia, Fernando;Ingeniero Informático y de Sistemas;Palomino Olivera, Emilio;"La búsqueda de archivos musicales está basada en texto o metadata como el título, autor, estilo musical y otros, pero este modelos no son adecuados, si deseamos encontrar canciones que se parezcan en contenido de audio o patrones musicales tales como ""notas musicales"", de allí la necesidad de modelar e implementar métodos de recuperación de información musical basado en audio musical, en este contexto surge la necesidad de obtener información de manera que la búsqueda no solo se limite a metadatos, sino también, exista métodos de recuperación musical que se ajusten a las exigencias de búsqueda del usuario, en este contexto es evidente la necesidad de emplear métodos que sean capaces de extraer o recuperar los contenidos musicales, del mismo modo intuitivo que en los documentos textuales. Aún hoy, las herramientas predominantes de uso generalizado para la búsqueda no presentan un enfoque basado en contenido musical, sino en su etiquetado textual. El objetivo del presente proyecto es implementar un prototipo de algoritmo para buscar música por Similitud de contenido para recuperar información musical en base a colecciones musicales a través del tarareo de una persona, para esto se trasforma archivos musicales en formato MP3 a archivos musicales de formato MIDI, el cual se implementó con librerías de JAVA denominados ""MIDI JAVA SOUND"", es así que mientras técnicas tradicionales permiten consultar documentos de una colección en base a metadatos, la recuperación de información musical explora el problema de recuperar un documento musical a partir de notas musicales (do, re, mi, fa, sol, la, si, do), y sus características semánticas, como intensidad y longitud de la nota musical, utilizando la metodología de cascada para el desarrollo del algoritmo, además se debe indicar que el algoritmo desarrollado se probó con 50 melodías en 10 usuarios obteniendo de un total de 500 intentos, una Tasa de Falso Rechazo (TFR) de 16 % y una Tasa de Falsa Aceptación (TFA) de 8 %, finalmente se concluye indicando que la estructura musical de una melodía contiene información de ritmo, estructura y referencias de notas sobre el pentagrama, es decir, datos acerca del estilo propio de una canción, lo cual permite realizar un análisis y búsqueda de patrones melódicos similares, entre el archivo musical y el tarareo utilizado con el fin de identificar un audio musical. El esquema que se utilizó para desarrollar el prototipo de algoritmo es el esquema de cascada, con el cual hicimos todos los pasos de dicho esquema secuencialmente para poder lograr el resultado final. El prototipo está inspirado en el requerimiento de las personas que al escuchar una música, parte de ella o un tarareo tienen la necesidad de saber quien canta la música o que tonada es, o cómo podemos ver en ejemplos de la vida real los ornitólogos siempre van en busca de una tipo de ave la cual tiene un sonido peculiar es así que con este software y utilizando el algoritmo que hemos desarrollado el ornitólogo va poder verificar donde se encuentra una determinada ave y a qué hora.";2016
Universidad Nacional de San Antonio Abad del Cusco;Implementación de una herramienta web para el apoyo en la elaboración de planes estratégicos de micro y pequeñas empresas;Huillca Diaz, Jhulian Jhasmani;Ingeniero Informático y de Sistemas;Candia Oviedo, Dennis Iván;"El presente proyecto de tesis consiste en implementar una Herramienta Web para el apoyo en la elaboración de planes estratégicos de Micro y Pequeñas empresas; el cual da como resultados estrategias. Estas estrategias son de suma importancia porque ayudaran en el desenvolvimiento inmediato de las Micro y Pequeñas Empresas y además servirán como base en la elaboración de un futuro plan estratégico. La Herramienta Web comenzará por obtener las características generales de la empresa, luego procederemos a realizar análisis y diagnósticos externos e internos de la empresa (Matriz Evaluación de Factor Externo EFE y Evaluación de Factor Interno EFI), seguido de un análisis de nivel competitivo (Matriz de Perfil Competitivo MPC ) , un análisis en la etapa de adecuación (Matriz Posición Estratégica y Evaluación de Acción PE y EA, Boston Consulting Group, Interna Externa, Estrategia Principal) y finalmente el análisis y elección de estrategias - etapa de decisión (Matriz de Planeación Estratégica Cuantitativa) la cual dará como resultado las estrategias operativas que debería aplicar la empresa. Esta Herramienta Web nos permitirá obtener además de Estrategias a seguir, un documento como resultado final del planeamiento estratégico, con el cual la empresa podrá cumplir sus objetivos.";2017
Universidad Nacional de San Antonio Abad del Cusco;"Propuesta de un marco de trabajo para la cláusula de adquisición, desarrollo y mantenimiento de sistemas de la ISO/IEC 27002:2013 ""Código de buenas prácticas para la gestión de la seguridad de la información"" para la oficina de tecnologías de información y comunicaciones de la EPS Sedacusco S.A.";Gonzáles Auccapuri, Fanny;Ingeniero Informático y de Sistemas;Palomino Olivera, Emilio;"El presente trabajo de tesis plantea el diseño de un marco de trabajo para la cláusula de Adquisición, Desarrollo y Mantenimiento de Sistemas bajo el enfoque de la Norma ISO 27002:2013 también denominada ""Código de Buenas Prácticas para la Gestión de Seguridad de la Información"" para la EPS SEDACUSCO S.A. Con la presente propuesta se busca responder a las exigencias de la organización en cuanto a la seguridad de la información. El objetivo del trabajo es analizar la situación actual de la empresa y mediante ello diseñar un marco de trabajo para la cláusula de Adquisición, Desarrollo y Mantenimiento de Sistemas bajo el enfoque de la Norma ISO/IEC 27002:2013 también denominada ""Código de Buenas Prácticas para la Gestión de Seguridad de la Información"" para la EPS SEDACUSCO S.A., demostrando que a través del desarrollo del mismo permitirá mejorar los lineamientos de seguridad de información y lograr un alto grado de seguridad para los activos de información de la empresa. Inicialmente se hace un análisis de la situación actual de los procesos involucrados directamente con el giro del negocio referentes a la cláusula de Adquisición, Desarrollo y Mantenimiento de Sistemas, después a partir de estas se elaboraran las secuencias de actividades y los diagramas de procesos para cada control de la cláusula antes mencionada. Seguidamente a partir de los pasos anteriores de hace la propuesta de los documentos que serán diligenciados para organizar la utilización e inclusión de los controles de la norma ISO/IEC 27002:2013 en los procesos de adquisición, desarrollo y mantenimiento de sistemas de la EPS SEDACUSCO S.A. Luego de haber identificado los principales procesos y establecido la línea de base de la documentación correspondiente, se diseñan e implementan los procesos documentados mediante un sistema de información desarrollado a partir del marco de trabajo, para que sea utilizado por los actores que participan en el diligenciamiento del cumplimiento de la cláusula de adquisición, desarrollo y mantenimiento de sistemas en la Oficina de Tecnologías de Información y Comunicaciones de la EPS SEDACUSCO S.A. Para realizar dicha propuesta se utilizó como herramienta de estudio la cláusula de adquisición, desarrollo y mantenimiento de sistemas de la norma ISO/IEC 27002:2013, de la cual se revisara e interpretara cada una de sus 3 categorías y los 13 controles que la conforman, es a partir de ello que se tendrá que establecer las bases para el diseño e implementación de la propuesta de marco de trabajo. En la EPS SEDACUSCO S.A. según mi experiencia personal de trabajo como practicante en la OTIC pude constatar que en la oficina no se utilizan los controles de seguridad de la cláusula de adquisición, desarrollo y mantenimiento de sistemas de la ISO/IEC 27002:2013 en los procesos que de desarrollo y soporte informático de la empresa.";2016
Universidad Nacional de San Antonio Abad del Cusco;Identificación de locutor usando codebooks de coeficientes cepstrales en las frecuencias de Mel y modelos ocultos de Markov;Mamani Condori, Errol Wilderd;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"El habla es un tipo de señal complicada producto del resultado de una serie de trans¬formaciones ocurridas en diferentes niveles: semántica, lingüística y acústica. Estas trans¬formaciones conducen a diferencias en las características de un individuo ampliamente estudiadas por la Biometría. La identificación de locutor (identificar quién es la persona que emitió la voz) en síntesis, es un análisis detallado de las características del habla de cada individuo basado en puntuaciones. En este contexto este proyecto se centró en la identificación de locutor mediante Coeficientes Cepstrales en las Frecuencias Mel o Mel Frequency Cepstral Cofficients (MPCC) y Modelos Ocultos de Markov o Hidden Markov Model (HMM). Iniciando el procesamiento de voz, para obtener las características más importantes de un individuo se utilizó Coeficientes Cepstrales en las Frecuencias Mel , debido a que en la actualidad otorgan los mejores resultarlos en el análisis Cepstral según el estado de arte, posteriormente; se hiso uso de la cuantificación vectorial o Vector quan- tization (VQ) que por medio del algoritmo de clasificación K-means ,divide el conjunto de vectores característicos en un número determinado de vectores representativos, los cuales mejoran sustancialmente el tiempo de procesamiento. Para el modelamiento de los de vectores representativos se hiso uso de los Modelos Ocultos de Markov; los HMMs son en¬trenados para generar el modelo oculto del locutor el cual estará formado por la secuencia de observaciones (símbolos de observación) y la secuencia de estados, para luego encontrar la secuencia de estados con mayor probabilidad, la identidad de un locutor se determi¬na mediante el modelo que obtenga la máxima probabilidad (puntuación) determinado por el algoritmo de Viterbi. Adicionalmente se estimaron los parámetros de los módulos de pre procesamiento, extracción de características, pos procesamiento v el cuantificador vectorial basado en codebooks; para sugerir el tamaño de codebook más adecuado y los parámetros con los que se obtenga buenos resultados en la identificación de un locutor ;para cada módulo se describió la teoría y la implementación del código fuente en Java. Finalmente, nuestros resultados experimentales muestran los parámetros con los que se obtienen buenos resultados teniendo un 90% de aceptación para un grupo reducido y cerrado de 5 personas en condiciones reales (con ruido de fondo), con una tendencia de decrecimiento a medida que aumenta el número de población y una mayor efectividad en condiciones ideales (ambiente cerrado y sin ruido de fondo).";2016
Universidad Nacional de San Antonio Abad del Cusco;Podoscopio electrónico para el diagnóstico de anomalías de la planta de pie;Huahuachampi Fernandez, Hirbin Jonatan;Ingeniero Informático y de Sistemas;Villafuerte Serna, Rony;"El pie plano y el pie cavo son patologías que causan molestias al caminar, dolor en el caso del pie cavo y del pie plano, un diagnóstico tardío implicaría desde molestias en la planta del pie hasta problemas en la postura de los pacientes. Cabe mencionar que en la ciudad del Cusco existen centros ortopédicos donde realizan diagnósticos de afecciones de la planta del pie, realizado de manera manual, a simple vista y basado en la experiencia del ortopedista, lo más grave es que una vez diagnosticado una afección del pie se inicia un tratamiento sin un control y registro adecuado de los efectos de este tratamiento, por lo tanto, es importante disponer de un dispositivo para el diagnóstico que sea capaz de registrar valores cuantificables en puntos estratégicos de la huella plantar y que contribuya a la interpretación médica. La presente tesis se muestra el diseño e implementación de un prototipo para la medición y diagnóstico de pie plano y pie cavo. Este dispositivo está conformado por una plataforma de vidrio, un foco, una cámara web y una caja de madera. La implementación del prototipo comprende en ubicar la cámara web y el foco dentro de la plataforma de manera tal que obtenga imágenes adecuadas para el procesamiento de éste mediante el lenguaje de programación MATLAB, el procesamiento de imágenes tiene cinco sub módulos; el primero “eliminar fondo”, consiste en eliminar áreas no utilizables del fondo de la imagen de entrada, que no es de interés en el procesamiento para el diagnóstico de patologías del pie, el segundo sub modulo consiste en determinar tres grupos con características comunes a la huella del pie para calcular puntos de interés, en este punto “hallar puntos de interés”, consiste en ubicar en la huella de la planta del pie el centroide de la pisada y el punto más extremo interno del mismo, en base a estos “dibujar líneas en posición”, para con estos datos calcular la distancia y el porcentaje del grado de mal formación del pie.";2017
Universidad Nacional de San Antonio Abad del Cusco;Plataforma web para comparación de secuencias génicas orientada al análisis de mutaciones de la proteína humana p53;Baca Muñiz, Yessenia;Ingeniero Informático y de Sistemas;Carbajal Luna, Julio Cesar;El presente trabajo de investigación tiene como objetivo el desarrollo de una plataforma web para las comparaciones de las secuencias génicas orientadas al análisis de las mutaciones de la proteína humana P53, cuyo propósito es saber si una secuencia génica se encuentra mutada o no y cuál sería el posible cáncer producto de la mutación. La proteína P53, guardián del genoma humano, o supresora de tumores, desempeña un papel muy importante en apoptosis y control del ciclo celular. Un p53 defectuoso podría permitir que las células anormales proliferen dando como resultado cáncer. La organización mundial de la salud nos indica que una de cada tres personas será diagnostica con algún tipo de cáncer en algún momento de su vida, gracias a la detección oportuna y actuales tratamiento se puede reducir a la mitad la letalidad del cáncer. Este proyecto pretende apoyar en el primer paso, como una herramienta para sirva en la detección de esta enfermedad y así formar una nueva cultura sobre el cáncer, eliminando los estigmas y ayudando de esta forma en las investigaciones en oncología. Para realizar la comparación y el análisis de las secuencias génicas utilizadas en el presente trabajo de investigación se hicieron uso de tres algoritmos: LCS (Longest Common Subsequence), Needleman-Wunsch y el algoritmo Hirschberg, obteniéndo mejores resultados con este último puesto que hace menor uso de los recursos en términos de tiempo de ejecución y uso de espacio de memoria. Una vez realizada la comparación y el análisis de las secuencias se pudo visualizar los resultados obtenidos a través de un reporte, en el cual se aprecia las posibles mutaciones y el posible cáncer sirviendo de esta forma como una herramienta muy útil en la lucha contra el cáncer.;2016
Universidad Nacional de San Antonio Abad del Cusco;Implementación de un portal web para el centro de investigación y producción de hongos alimenticios y medicinales de la Universidad Nacional de San Antonio Abad del Cusco;Chambi Yupa, Rusbel Nadine;Ingeniero Informático y de Sistemas;Flores Pacheco, Lino Prisciliano;"Hoy en día los sitios web se han convertido en una de las opciones de mayor consulta y divulgación para la sociedad actual, siendo uno de los medios de comunicación más rápidos y entretenidos; es así como nace la necesidad de implementar un portal web que permita a los integrantes del Centro de Investigación y Producción de Hongos Alimenticios y Medicinales (CIPHAM) divulgar sus conocimientos e investigaciones a la población. El objetivo general de este proyecto es el de implementar un portal web que permita al usuario mantenerse informado acerca de las actividades, noticias y eventos que realiza CIPHAM, accediendo a información actualizada, visualizar un mapa que muestre en infowindows los datos característicos de los hongos alimenticios y medicinales, su ubicación geográfica de los lugares de producción y recolección, además de interactuar con las opiniones del público mediante un sistema de comentarios. Gracias a la aceptación por parte de los involucrados a este proyecto (integrantes de CIPHAM) se puede concluir que la creación de este tipo de aplicaciones permite aprovechar de mejor manera la tecnología como un medio de difusión. El proyecto fue desarrollado bajo la metodología descriptiva, analizando cual es el problema y su entorno para darle una solución óptima., y para la aplicación el Proceso Único de Desarrollo de Software (PUDS), utilizando herramientas de código abierto como base de datos MySQL, editor de texto Sublime y Dreamweaber, y para la implementación del gevisor se hace uso del API Google Maps para acceder a sus funciones y personalizar los mapas.";2017
Universidad Nacional de San Antonio Abad del Cusco;Virtualización de aplicaciones para mejorar el acceso y consultas a los sistemas registrales de la superintendencia nacional de registros públicos-sede Cusco desde la oficina registral de Quillabamba utilizando citrix xenapp;Saavedra Soras, Ivonne;Ingeniero Informático y de Sistemas;Peñaloza Figueroa, Manuel Aurelio;El presente proyecto da a conocer el procedimiento para virtualizar sistemas registrales de la zona registral N° X utilizando la solución citrix XenApp. Para ello fue necesario implementar en la Unidad de Tecnologías de la Información un servidor de aplicaciones donde están instalados los sistemas registrales y un servidor de infraestructura donde se configuró las funcionalidades de citrix XenApp. También se realizó un análisis del nivel de satisfacción de los usuarios utilizando aplicaciones virtuales. Con este proyecto se busca centralizar infraestructura e información y así mejorar su administración sin perjudicar la interacción de los usuarios de la oficina registral de Quillabamba con los sistemas registrales virtualizados.;2016
Universidad Nacional de San Antonio Abad del Cusco;Aplicación móvil para apoyar la promoción del turismo en el centro histórico del Cusco, utilizando realidad aumentada y geolocalización;Taipe Mayhua, Yanet;Ingeniero Informático y de Sistemas;Palomino Olivera, Emilio;El presente trabajo de investigación busca desarrollar una aplicación móvil con información centralizada de atractivos turísticos del Centro Histórico de Cusco ofertados en el circuito II del boleto turístico así como de aquellos atractivos turísticos administrados particularmente, esta aplicación ofrece mostrar la ubicación de puntos de interés a través del uso de las tecnologías de realidad aumentada y mapas, implementar sistemas de búsqueda de puntos de interés, y mostrar información como descripciones, fotografías, información sobre horarios de visitas, la tarifa de costo. En el desarrollo de este proyecto se hizo uso de la metodología ágil SCRUM por tratarse de un proyecto con un tiempo limitado. El resultado obtenido brindó al turista una herramienta tecnológica usando la realidad aumentada en el smartphone que le permita acceder a información relevante de los atractivos turísticos y de esta manera mejorar la experiencia, de acceso a la información del turista durante su visita. Por lo que se concluye que la aplicación móvil contribuyó con la difusión de los atractivos turísticos del Centro Histórico de Cusco a través de una aplicación móvil innovadora haciendo uso de un Smartphone cuyo beneficio al turismo es el de brindar información real y exacta de los principales lugares del Centro Histórico de Cusco. La aplicación debe ser fácil e intuitiva de utilizar de tal manera que cualquier tipo de usuario sea capaz de operarla. Esta aplicación fue implementada para la Dirección Desconcentrada de Cultura Cusco (DDC - CUSCO) por parte de la Oficina de Informática y Sistemas con el nombre de “DISCOVER CUSCO”.;2017
Universidad Nacional de San Antonio Abad del Cusco;Conversor de texto escrito a voz por concatenación de difonemas para el idioma quechua;Sánchez Espirilla, Gabriela;Ingeniero Informático y de Sistemas;Palma Ttito, Luis Beltrán;"La presente tesis tiene corno fin implementar un conversor de texto a voz, herramienta tecnológica, utilizando la técnica de concatenación de unidades básicas ""difonemas"", para la síntesis de voz del idioma1 quechua con alfabeto pentavocálico y frecuente en la región Cusco. Se identificaron dos momentos claves para llevar a cabo el trabajo. Primero, se construyó el corpus de voz y la base de datos para dicho idioma. Para lo cual, inicialmente, se identificaron los difonemas válidos y propios del idioma quechua; para ello, previamente, se realizó una aproximación al estudio de la lingüística del idioma. Seguidamente, se realizaron las grabaciones de las frases y palabras portadoras de dichos difonemas; esto para el etiquetado y extracción de los mismos. La información obtenida en este punto sirvió para la construcción de la base de datos de difonemas para el idioma quechua. Segundo, se construyó el sintetizador de voz. Para lo cual, se identificaron dos bloques, del procesamiento del lenguaje natural, y del procesamiento digital de la señal. El primer bloque comprende la extracción y el análisis de la oración para la elaboración del fichero de transcripción fonética de los difonemas que componen dicha oración. El segundo bloque se encarga de procesar la transcripción obtenida en el bloque anterior con la ayuda de diferentes algoritmos para convertirla en voz. Este utilizó una técnica llamada TD-PSOLA y otras para suavizar la unión de difonemas. La creación de la herramienta en mención; así como, su uso y futura mejora; aprovecha las ventajas de las tecnologías del habla y conversión de texto a voz para aspirar ser un ejemplar de aquellas escasas tecnologías de información y comunicación para idiomas confinados al hogar y a generaciones mayores2 como el quechua. Este busca democratizar el acceso a la información y los avances tecnológicos a personas quechua hablantes buscando desarrollar capacidades. Además, ésta busca rechazar la idea que el idioma quechua resulta inadecuado para transmitir los avances y desarrollos de las ciencias y las artes. Dicho de esta manera, es notable la ausencia de herramientas tecnológicas para la enseñanza del idioma quechua en diferentes campos donde podría complementar los aprendizajes, para ejemplo están los proyectos de alfabetización y educación intercultural bilingüe, sistemas de lectura para invidentes, entre otros. En conclusión, se implementó un conversor de texto escrito a voz utilizando la estrategia de concatenación de difonemas para el idioma quechua de la familia lingüística denominada Cusco - Collao.";2016
Universidad Nacional de San Antonio Abad del Cusco;Prototipo de oximetría, para el monitoreo de personas propensas al soroche, en la región del Cusco;Valencia Flores, Alex Raul;Ingeniero Informático y de Sistemas;Pillco Quispe, José Mauro;En este trabajo se presenta una alternativa adecuada y económica para el monitoreo de la saturación de oxígeno en la sangre (SpO2 %), en turistas visitantes a la Ciudad del Cusco, mediante el diseño y construcción de un prototipo de oximetría portátil colocado en la oreja del paciente ya que en ésta parte del cuerpo los sensores de luz del prototipo obtienen los valores de SpO2 (%), mediante los principios de absorción de luz y la ley de Lambert-Beer, la implementación del dispositivo se realiza con componentes comerciales en nuestro medio y reciclados, este prototipo utiliza protocolos de comunicación Bluetooth, para enviar datos y reportes detallados del estado del oxígeno en el organismo a un teléfono móvil y este a su vez envía ésta data a un servidor. La puesta a prueba del prototipo y recolección de datos se realizará en la Ciudad del Cusco, en aproximadamente cuatro visitantes de entre 20 y 70 años de edad, obteniéndose diagnósticos aproximados al 100 % de confiabilidad, los cuales son contrastados con los síntomas de los turistas a cargo de un guía oficial de turismo.;2016
Universidad Nacional de San Antonio Abad del Cusco;Implementación de un juego matemático educativo basado en realidad aumentada para la enseñanza de primer grado de primaria;Huamanttica Salas, Eric Rodrigo;Ingeniero Informático y de Sistemas;Palma Ttito, Luis Beltran;En el presente proyecto se implementó un juego educativo cuyo objetivo es servir como apoyo al aprendizaje en matemática para niños que cursan el primer grado de primaria, haciendo uso de la tecnología de Realidad Aumentada para relacionar las matemáticas con el niño de manera interactiva y en tiempo real. El juego educativo hace uso, para su funcionamiento, de los cuatro elementos básicos que conforman un sistema de Realidad Aumentada como: cámara web (elemento capturador) componente que permite capturar la imagen del niño que sostiene en su mano el marcador (elemento de situación) y que se encuentra frente a la misma para luego ser transferido al software educativo (elemento procesador) éste interpreta los datos capturados del entorno real y lo convierte en todo tipo información, en este caso: números, objetos, operaciones matemáticas, figuras geométricas y sonido. Cabe mencionar que para la implementación del juego educativo se utilizó la plataforma EmguCV, la cual permite llamar a las funciones de la librería de procesamiento de imágenes OpenCV desde el lenguaje de programación utilizada en dicha implementación (C#). Así mismo el proyecto propone las posibilidades del uso de tecnologías para su utilización lúdica en la educación, haciendo algunas consideraciones sobre la importancia del juego para el apoyo en el aprendizaje de matemáticas. Finalmente se defiende la importancia de los planteamientos lúdicos para el aprendizaje basado en el uso de tecnología ya que el juego planteado en el presente proyecto con soporte informático es diseñado con fines educativos a través del cual se pretende desarrollar capacidades de aprendizaje. En la investigación, la hipótesis relaciona las variables inmersas en el estudio: “La implementación de un juego educativo matemático basado en realidad aumentada, contribuirá en el aprendizaje en niñas y niños en el primer grado de educación primaria del proceso de enseñanza”, utiliza el tratamiento estadístico, permitiendo realizar la prueba de la hipótesis planteada y determinar el efecto del uso de juego educativo planteado en el proyecto, la investigación es de diseño pre-experimental con dos grupos apareados, uno experimental y otro de control, aplicándose test de salida de conocimientos conceptuales, procedimentales y actitudinales, para con el tratamiento estadístico T – Student, probar la hipótesis ya mencionada.;2017
Universidad Nacional de San Antonio Abad del Cusco;Aplicaión móvil para el aprendizaje de matemáticas de los niños con el sindrome de down en el centro de educación basica especial nuestra señora del carmen;Rayan Suni, Orfelinda;Ingeniero Informático y de Sistemas;Candia Oviedo, Dennis Ivan;El presente trabajo de investigación consistió en el desarrollo de una Aplicación Móvil, para el aprendizaje de números en el Área de Matemáticas para los niños con Síndrome de Down, en edades de 8 a 12 años con tecnología móvil. Para el desarrollo de la investigación, se usó la metodología de investigación de recopilación mixta de datos documentales, de campo y experimentales, debido a que se recopilo información documental del campo a través de análisis de información e interpretación obtenido en un ambiente para efectuar pruebas controladas en un marco experimental. Y por existir la construcción de una herramienta cuyo propósito es mejorar la calidad de vida de determinados usuarios, se usó metodología de investigación tecnológica, y finalmente para el desarrollo de la aplicación se utilizó la metodología de programación ágil XP(extreme programing). Las actividades que forman parte de la Aplicación requieren una Tecnología móvil (Tablet o Smartphone) para su funcionamiento, cada una de ellas ha sido desarrollada respetando las actividades curriculares que rigen en educación especial e integrándolas a una tecnología móvil, todo esto hizo que el aprendizaje de números en el área de matemáticas fuera un proceso más novedoso e interactivo, donde los resultados obtenidos fueron de mayor beneficio para el niño con Síndrome de Down. Los niños para interactuar sin problemas con la Aplicación, deberán reconocer y familiarizarse con esta tecnología. Es ahí donde inicia la experiencia del niño con Síndrome de Down con la tecnología móvil, cumpliendo el objetivo trazado. Siendo así el resultado de la investigación una Aplicación Móvil que mejora el aprendizaje de números en el área de matemáticas, enfatizando la parte cognitiva, brindando oportunidades innovadoras a estos niños, para un mejor desenvolvimiento y perfeccionamiento de su aprendizaje en el entorno actual (Sociedad informática).;2017
Universidad Nacional de San Antonio Abad del Cusco;Implementación de un prototipo de datawarehousing como soporte a la toma de decisiones del Hospital Nacional Adolfo Guevara Velasco Essalud-Cusco;Clemente Taco, Oscar Abel;Ingeniero Informático y de Sistemas;Rozas Huacho, Javier Arturo;"El directorio del Hospital Nacional Adolfo Guevara Velasco – ESSALUD – Cusco, realiza programaciones de demanda de pacientes a ejecutarse en las distintas Unidades Productoras de Servicios de Salud (UPSS), donde la toma de decisiones para una programación más eficiente de demanda de pacientes, especialmente en la UPSS de Emergencia, hace necesaria la implementación de una herramienta de toma de decisiones para poder predecir la cantidad de demanda de pacientes a ejecutarse el mes siguiente, para satisfacer mejor la demanda de los pacientes, la cual crece constantemente. Para lograr este objetivo, se ha creado un Data Warehouse(DW) creado principalmente a partir de la base de datos transaccional del Sistema de Gestión Hospitalaria (SGH), que está conformado por los Data Marts(DM) de cada UPSS los cuales son explotados mediante técnicas de Bussiness Intelligence (BI) y Bussiness Analytics (BA). Por lo que el presente proyecto de tema de tesis plantea, en una primera etapa una solución de BI, que implica el proceso de Extracción, Transformación y Carga de datos (ETL), construcción del DW enfatizando en el DM de Emergencias, creación de cuadros de mando con cubos (On-Line Analytical Processing)OLAP desarrollado mediante la plataforma Pentaho y como gestor de base de datos SQL Server para la implementación del DW; teniendo así la información limpia y ordenada para que en una segunda etapa, con una solución de BA se efectúe la explotación de la data de la UPSS de Emergencias, modelando así la demanda de pacientes de los tópicos de Emergencia en series de tiempo, para ofrecer una predicción de la demanda en futuros periodos, lo que servirá al experto como soporte para tomar decisiones con respecto a la programación de atención de guardias médicas, utilizando modelos de predicción basados en las técnicas de Box-Jenkins y Holt-Winters. Finalmente, para obtener un mejor resultado se ha de calibrar los modelos predictivos en la fase de pruebas escogiendo el mejor modelo de predicción por tópico de emergencia.";2017
Universidad Nacional de San Antonio Abad del Cusco;Seguridad en el desplazamiento de personas invidentes basado en tecnologías móviles;Huillca Malmorejo, Thony;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;EI presente trabajo propone el diseño de un sistema integral para la seguridad en I desplazamiento de personas invidentes basado en tecnologías móviles el cual servirá como gula asistida por el Smartphone y el detector de obstáculos mediante sensores de ultrasonido el cual facilitara su desplazamiento de manera segura y confiable. Se logró diseñar un dispositivo que permite la detección de obstáculos, el cual es aplicado a apoyar a personas en condición de discapacidad visual a movilizarse de una manera más segura, llegando a ofrecer lecturas confiables con una precisión de 5 cm hasta una distancia de 4.50 metros. El resultado final del sistema se estableció como una adaptación del bastón tradicional usado comúnmente por las personas invidentes, instalándole un sistema de detección de obstáculos en tres niveles, para facilitar su movilidad día a día, además se complementa con una aplicación para celulares que utiliza herramientas para facilitar la ubicación espacial del invidente.;2016
Universidad Nacional de San Antonio Abad del Cusco;Algoritmo de optimización basado en el comportamiento social de las arañas para clustering;Soncco Alvarez, Jose Luis;Ingeniero Informático y de Sistemas;Enciso Rodas, Lauro;"Clustering es una técnica popular de análisis de datos para identificar grupos homogé¬neos de objetos basado en los valores de sus atributos, utilizado en muchas disciplinas y aplicaciones. En este trabajo utilizamos el algoritmo de optimización basado en el compor¬tamiento social de las arañas (SSO) para optimizar grupos de datos tomando como métrica la suma de distancias euclidianas. El algoritmo SSO, propuesto por Cuevas et al., se basa en la simulación del comportamiento social cooperativo de las arañas. Los individuos usa¬dos en este algoritmo son arañas (macho y hembra) que interactúan entre sí basados en el comportamiento cooperativo de una colonia de arañas; este comportamiento es la directriz para el funcionamiento de este algoritmo. En este trabajo el algoritmo SSO fue analizado, adaptado e implementado para optimizar el problema de Clustering. Para efectos de com¬paración fueron implementados otros algoritmos importantes de la literatura: el algoritmo K-means y un algoritmo genético (AG) adaptado a el problema de Clustering. Experimentos fueron realizados usando 5 datasets tomados del repositorio UCI Machine Learning Reposi¬tory, cada algoritmo fue ejecutado varias veces y después fueron calculadas varias medidas como: promedio, mediana, mínimo, y máximo valor de los resultados. Estos experimentos mostraron que el algoritmo SSO supera al algoritmo K-means y obtiene resultados igual de competitivos que el AG. Todos estos resultados fueron confirmados por la prueba estadística no paramétrica de Wilcoxon realizada sobre las salidas de los algoritmos.";2016
Universidad Nacional de San Antonio Abad del Cusco;Sistema de posicionamiento en lugares cerrados mediante el uso de dispositivos de bluetooth;Yunguri Fernandez, Wilson;Ingeniero Informático y de Sistemas;Carrasco Poblete, Edwin;"En la actualidad, determinar la ubicación de un individuo u objeto es de suma importancia y más aún si este se encuentra en el interior de un edificio; situaciones en las que personas debido a su nivel de importancia dentro de una organización, grupos de riesgo o por beneficio personal necesiten ser encontradas. Esta tarea puede ser tediosa en términos de pérdida de tiempo y baja probabilidad de hallar al individuo sobre todo si no se tiene indicio de donde está. El presente trabajo de investigación titulado “Sistema de posicionamiento en lugares cerrados mediante el uso de dispositivos Bluetooth”, consiste en el desarrollo de un sistema que permite conocer la posición o ubicación de un dispositivo móvil (teléfono celular) en el interior de un ambiente cerrado. El sistema está compuesto por dos sub sistemas, un aplicativo móvil y otro aplicativo de escritorio (servidor); la aplicación móvil ha sido desarrollada para la plataforma Android, la cual interactúa mediante una Piconet de Ibeacons (balizas Bluetooth) y mediante la captura de intensidades de señal (RSSI) y el uso del método de trilateración determinara su ubicación. El sistema móvil haciendo uso de las señales Wifi interactuara con el servidor enviando su posición en un paquete de datos el cual será procesado para ser accedido por el administrador o cualquier otro usuario móvil que lo solicite.";2016
Universidad Nacional de San Antonio Abad del Cusco;Desarrollo de una propuesta de implementación de la ntp iso/iec 27001 :2014, sistema de gestión de seguridad de la información, para la oficina funcional de informática del gobierno regional Cusco;Quispe Borda, Sheny Katerine;Ingeniero Informático y de Sistemas;Palomino Olivera, Emilio;"La Oficina Funcional de Informática del Gobierno Regional del Cusco actualmente no cuenta con la implementación de controles eficientes, normas y estándares relacionados a seguridad de la información, siendo la información su activo más importante. Por tanto en respuesta a este problema se desarrolla el presente trabajo de tesis, que muestra las etapas de diseño y planificación de un Sistema de Gestión de Seguridad de la Información alineado a las especificaciones y requisitos de la NTP ISO/IEC 27001:2014, adaptando este proceso al contexto de la Oficina Funcional de Informática; para lo cual se adquirió y utilizó la NTP ISO/IEC 27001:2014 para su revisión e interpretación, logrando así identificar los procesos claves de las etapas de desarrollo del proyecto, las cuales son: Organización, Planificación, Despliegue, Revisión y Consolidación. El objetivo de este trabajo es elaborar una propuesta de implementación de los requisitos especificados del capítulo 4 al 10 de la NTP ISO/IEC 27001:2014 que se exigen para la conformidad de un Sistema de Gestión de Seguridad de la Información. Inicialmente se realiza un diagnóstico de la situación actual de la Oficina Funcional de Informática en relación al cumplimiento de los requisitos de la norma, logrando así identificar las debilidades y falencias en temas de seguridad de la información relacionados al cumplimiento de la norma. A continuación se identifican los procesos y actividades a llevarse a cabo en cada etapa del desarrollo del proyecto el cual es alineado a la metodología PHVA (Planificar, Hacer, Verificar y Actuar) donde a su vez se aplicaron conceptos y directrices sobre la gestión de proyectos utilizados en la guía PMBOK; posteriormente en los anexos del trabajo se realiza la documentación de los entregables que son exigidos en la norma. Finalmente el desarrollo de esta propuesta es considerada para la institución como una guía y soporte para el inicio de las actividades de implementación de un Sistema de Gestión de Seguridad de la Información como es exigido por ley (RM N° 004-2016-PCM).";2017
Universidad Nacional de San Antonio Abad del Cusco;Diseño e implementación de un sistema portátil de historial clínico electrónico para un control médico de mascotas;Huarancca Rimachi, Avelino;Ingeniero Informático y de Sistemas;Carrasco Poblete, Edwin;El presente trabajo se centra en el desarrollo de diseño de un prototipo electrónico y de un sistema informático de historial clínico para mascotas, proporcionando una herramienta que contribuya al control de información clínica y básica de mascotas. Bajo este criterio, el objetivo principal se enfoca en la obtención del diseño e implementación final de un sistema de información veterinaria, con el fin de tener información clínica portátil en las diferentes clínicas u hospitales de mascotas, para este proyecto los requerimientos del sistema y el dispositivo se realizó en base a los veterinarios de la clínica de mascotas Gomes, ubicada en Calle Retiro 304, Wanchaq - Cusco. Se detalla el desarrollo tecnológico del diseño del prototipo del sistema, mediante el diseño de un subsistema de comunicación por Bluetooth, memoria de almacenamiento de historial clínico y la implementación de un subsistema de información de seguimiento de datos. La historia clínica electrónica supone incorporar las tecnologías de información y la comunicación en el núcleo de la actividad sanitaria. Esto trae como consecuencia que la historia clínica, en este caso de mascotas deje de ser un registro simple información, siendo información generada en la relación entre un paciente y un profesional veterinario médico o un centro sanitario para formar parte de un sistema integrado de información clínica. Es así que la historia clínica electrónica es el registro unificado e individual en la que se archiva mediante un soporte electrónico toda la información referente al paciente y su atención médica. Por lo tanto es indispensable integrar esta información que se utiliza en la práctica clínica, almacenar adecuadamente hacerla amigable, accesible y difundirla de forma adecuada a los posibles usos y con las garantías debidas (consentimiento, confidencialidad y demás requisitos), y recibirlas y reutilizarlas en la forma más adecuada en un proceso médico.;2017
Universidad Nacional de San Antonio Abad del Cusco;Reconocimiento de somnolencia en conductores bajo condiciones simuladas;Paucara Núñez, Frederick Jacinto;Ingeniero Informático y de Sistemas;Cruz Tello, Juan Antonio;"La somnolencia en conductores es una de las causas de accidentes de tránsito, por lo cual detectar el estado de somnolencia y advertir al conductor es una forma de solucionar este problema. Este proyecto tiene como objetivo principal la utilización de algoritmos de detección de objetos para reconocer el estado de somnolencia en conductores, por lo que debe trabajar con información visual obtenida del rostro del conductor. Para reconocer el estado de somnolencia se capturan fotogramas del conductor usando una webcam, cada fotograma es evaluado buscando primero detectar un rostro, si un rostro es detectado entonces se evalúa el estado de los ojos (""abiertos"" o ""cerrados""), con la información del estado de los ojos de los 10 últimos fotogramas se calcula el porcentaje de ojos cerrados o PERCLOS, para un PERCLOS mayor a 40% consideramos que el estado de somnolencia del conductor es peligroso y se muestra una señal de alarma. Las pruebas se realizaron bajo las condiciones simuladas siguientes: Luz natural diurna, una webcam de 640x480 píxeles ubicada a una distancia de 40 a 60cm del conductor y a la altura del volante de un auto sin movimiento, se obtuvo un error de hasta 8% en la clasificación de ojos ""abiertos"" o ""cerrados"", se utilizó el algoritmo de detección de objetos de Viola & Jones implementado en la librería OpenCV para ubicar el rostro y buscar ojos abiertos usando el lenguaje de programación C#, este algoritmo tiene buen desempeño en ojos con apertura de párpados mayores a 7mm, y con un índice PERCLOS > 40% la señal de alarma es mostrada en un tiempo promedio de 299ms desde que se detectaron los ojos cerrados.";2013
Universidad Nacional de San Antonio Abad del Cusco;Desarrollo de una aplicación web orientada a servicios para el monitoreo de una flota de vehículos haciendo uso de la tecnología GPS;Conza Berrocal, Mary Helen;Ingeniero Informático y de Sistemas;Carrasco Poblete, Edwin;"El presente trabajo de investigación trata acerca del desarrollo de una aplicación georefencial, cuyo propósito es el de rastrear y monitorear una flota vehicular para una operadora de taxis que labora a nivel local. El desarrollo metodológico del proyecto se basa en el método descriptivo, esquema usado para recopilar datos y capturar los requerimientos de la empresa en cuestión. Para la aplicación web se emplea las especificaciones del Proceso Unificado de Desarrollo de Software (PUDS). Los vehículos están equipados con receptores -GPS que incluyen módem inalámbrico, estos dispositivos calculan su respectiva posición, hora y velocidad; dichos parámetros son enviados mediante la red celular GSM/GPRS de manera automática a una estación central haciendo uso de los servicios web REST. En la estación central se procesan los parámetros y son almacenados en la base de datos MySQL del servidor web Apache; al mismo tiempo, envía esos datos mediante el uso de web sockets a las máquinas cliente, que en ese momento están rastreando los vehículos en tiempo real, dichas máquinas clientes visualizan la ubicación de los vehículos en un mapa que provee Google Maps. El resultado de la investigación es un aplicativo que rastree una flota vehicular en tiempo real, a fin de contribuir al estudio de los sistemas de información geo-referencial y su implementación con tecnologías móviles que hoy en día tenemos al alcance.";2013
Universidad Nacional de San Antonio Abad del Cusco;Diseño e implementación de componentes de software para el desarrollo de aplicaciones Scada;Salcedo Moreno, Darío César;Ingeniero Informático y de Sistemas;Carrasco Poblete, Edwin;"Después de haber sido desarrolladores durante muchos años, hemos alcanzado el punto en el que programar empezaba a cansamos y aburrimos, perdiendo poco a poco el disfrute que nos causaba implementar aplicaciones, esto debido entre otras cosas porque las herramientas de las que disponíamos nos hacían pensar en que ya se hizo todo, no hay mucho que explorar o porque los planes que teníamos no los podíamos llevar a cabo a causa de sus limitaciones. Entonces llego Microsoft Visual Studio 2008 con su tecnología WPF y su suite de nuevas y excitantes herramientas de Microsoft Expression Studio, que abrió todo un mundo de posibilidades, un nuevo despertar que por fin resuelve cosas con las que hemos estado luchando a brazo partido por mucho tiempo. En lo referente a empresas industriales, cabe destacar que uno de los objetivos es optimizar los sistemas de control, el cual les permita la utilización eficiente de los recursos, reduciendo tiempos de preparación, minimizando errores, eliminando tiempos de espera, logrando un flujo continuo en la línea de producción, minimizando los transportes internos, evitando retrasos, etc. Ofrecer entonces un sistema de información a estas empresas, el cual les ayude a lograr sus objetivos es una tarea esencial, pero el mero hecho de intentar abordar este problema no resultaba sencillo debido a las limitaciones innatas con las que cuentan los lenguajes de programación tradicionales. Desarrollar un sistema de información para visualizar la evolución de un proceso o averiguar el estado de una variable como por ejemplo el caudal de una mezcla, implicaba tener que construir un control de usuario para llevar a cabo esta función, lo cual cabe indicar que era una tarea muy compleja que implicaba tener un profundo conocimiento sobre el sistema grafico del lenguaje y tener mucho tiempo disponible, para desarrollar aplicaciones con ellos, tarea que al final muchas veces no siempre resultaba satisfactoria.
Esta problemática, unida a las ideas que teníamos rezagadas durante mucho tiempo, por fin pueden ser abordadas con relativa facilidad, haciendo uso de WPF y el paquete Expression Studio, el cual nos devuelve la emoción de escribir código otra vez, nos hace levantar cada mañana pensando en todo lo nuevo y fabuloso que aprenderemos en el día. Este proyecto de titulación surgió entonces como un reto para poner en práctica nuestra habilidad y conocimientos, descubrir la potencia de estas herramientas y sobre todo ofrecer a la comunidad de desarrolladores, componentes que faciliten la implementación de sistemas de información industriales, que proporcionen una ventaja competitiva frente a la constante y dura competencia que hoy en día poseen todas las empresas, dotándolas de información veraz y oportuna para la toma de decisiones.
El resultado de este proyecto será una herramienta eficaz y oportuna que permitirá a los desarrolladores de aplicaciones orientados al campo industrial, realizar su trabajo de manera más fácil y segura en base a los controles que ofrece el proyecto, optimizando tiempos de desarrollo y porque no costos.";2013
